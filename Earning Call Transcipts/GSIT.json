[
    {
        "symbol": "GSIT",
        "quarter": 3,
        "year": 2024,
        "date": "2024-01-25 18:41:02",
        "content": "Operator: Ladies and gentlemen, thank you for standing by. Welcome to GSI Technology's Third Quarter Fiscal 2024 Financial Results Conference Call. At this time, all participants are in a listen-only mode. Later, we will conduct a question-and-answer session. At that time, we will provide instructions for those interested in entering the queue for the Q&A. Before we begin today's call, the company has requested that I read the following safe harbor statement. The matters discussed in this conference call may include forward-looking statements regarding future events and the future performance of GSI Technology that involve risks and uncertainties that could cause actual results to differ materially from those anticipated. These risks and uncertainties are described in the company's Form 10-K filed with the Securities and Exchange Commission. Additionally, I've been asked to advise you that this conference call is being recorded today, January 25, 2024, at the request of GSI Technology. Hosting the call today is Lee-Lean Shu, the company's Chairman, President and Chief Executive Officer. With him are Douglas Schirle, Chief Financial Officer; and Didier Lasserre, Vice President of Sales. I would now like to turn the conference over to Mr. Shu. Please go ahead, sir.\nLee-Lean Shu: Good afternoon, and thank you for joining us. I am pleased to share several key updates from an eventful third quarter. Starting with the product development, we achieved two major milestones that will keep us on track to advance the Gemini APU family. First, in November, we successfully completed the radiation-hardened testing on the Gemini-I APU for compute-in-space applications. The test results confirm that Gemini-I has met characteristics to be a radiation-tolerant processor. We are actively engaged with several satellite companies that need radiation-tolerant APUs, and we are encouraged by the strong interest. Moving to our next-generation APU, we completed the table of Gemini-II in the third quarter. In late February, we will evaluate the initial spin and expect to begin sampling Gemini-II chip in the second half of calendar 2024. Gemini-II has 8 times of internal memory and 10 times better performance than Gemini-I and notably lower cost. This dramatically improve in cost performance allow us to target a much broader range of applications. The 96-megabyte of internal memory in Gemini-II can fit many AI models entirely on the chip, enabling in-place data processing without accessing external memory, external [DRAM] (ph). This should give Gemini-II tremendous advantage on compact edge applications like drone and ADAS. We anticipate starting initial alpha deployment with select customers in the second half of calendar 2024. Lastly, in the third quarter, we shipped radiation-hardened SRAMs to two customers for two new programs and we received a second SBIR Direct-to-Phase II contract in the amount of $1.1 million. Looking ahead, we are in the early stage of developing the architecture for our next-generation Gemini-III chip. We had a discussion with several hyperscalers about APU design options to best address the emerging markets' need in the data center. In addition to helping hyperscalers lower data center power consumption, the APU can also provide significant benefit to GenAI end users by reducing inference costs. We initiated preliminary discussion with two major hyperscalers who have expressed interest in our technology and continue to work with internal teams on various early-stage concepts. Turning to our financial performance, the third quarter revenue of $5.3 million met our guidance, with a gross margin of 56% was at the midpoint of our guidance. The sequential improvement in gross margin reflects product mix this quarter. Our operating expenses, which increased both year-over-year and sequentially, included a one-time expense of $2.4 million for pre-production mask for Gemini-II. We view this as an investment in future growth as Gemini-II will greatly expand APU market reach. In parallel, we continue discussion with potential strategic partners to support Gemini-II launch and assist with Gemini-III development. As our most ambitious chip today, we anticipate that Gemini-III will require significant capital investment and partnership to help mitigate our funding needs. We remain focused on food and financial management to fuel our product roadmap and expansion into new markets. Recently, Cornell University published a research paper, spotlighting the unique efficiency of our Gemini-I APU to accelerating location filtering in DNA mapping. Didier will discuss the detail of the paper and its implications for GSI in his comments. In closing, it was an eventful third quarter with tremendous progress on our Gemini roadmap, prudent expense management and action to increase our financial flexibility to support our growth. We remain laser-focus on bringing our innovative APUs to market and driving long-term value creation. Now, I will hand the call over to Didier, who will discuss our business performance further. Please go ahead, Didier.\nDidier Lasserre: Thank you, Lee-Lean. I want to provide some additional context on why we are so confident in the market potential for our APU architecture, especially for inference workloads. First, the unmatched flexibility of our variable bit processing is key. With 2 million undefined bit processors that can be toggled from 1 bit to 2 million bits cycle by cycle, our APU can adapt to real time -- I'm sorry, in real time to maximize efficiency. This dynamic bit-wise configurability can process long strips 1 bit at a time and is ideal for inference since research shows that different bit precisions are more efficient for different models. Second, our APU architecture breaks the Von Neumann model by removing the data fetch function. This innovative design delivers higher performance with lower power consumption. As Lee-Lean mentioned, these capabilities directly address the critical needs of data centers and emerging applications by lowering data center power consumption and reducing inference costs for GenAI end users. Importantly, I want to emphasize that our APU represents true in-memory -- I'm sorry, true compute-in-memory architecture. Unlike competing chips that claim compute-in-memory, they are actually near memory compute, and our APU has logic physically integrated in the memory. This fundamental difference in architecture will ultimately enable our APU to achieve the transformative speed and efficiency gains we anticipate as we scale. Our true compute-in-memory architecture gives us a sustained competitive advantage. To accelerate ecosystem development, we are focusing on getting APU in the hands of key partners in the military, hyperscalers and academia. The real-world deployment and libraries will showcase the benefits, expand use cases, and support our go-to-market capabilities. One example of the strategy is helping us promote and monetize Gemini-I is a recently published research paper from Cornell University. We are pleased to announce that the Cornell paper demonstrates our APU one -- I'm sorry, Gemini-I APU's unique performance benefits for genomic applications. Leveraging the APU's massively parallel in-memory architecture, Cornell researchers showed up to 6 times faster DNA sequencing filtering compared to a 16-core CPU. This showcases our technology's advantage for data-intensive workloads requiring rapid, low-precision comparisons. The study also revealed strong potential to accelerate other applications with similar data-matching needs, including medical data analysis, search, security, and more. With simple scaling, our APU can be packed into cost-effective high-density servers to multiply this performance for real-world deployments that can lower power budgets for hyperscalers compared to GPU solutions. These results enforce -- I'm sorry reinforce our significant market opportunities across sectors that rely on efficiently finding patterns and similarities within massive data sets. We remain focused on delivering the game-changing in-memory compute performance to customers across multiple industries. As Lee-Lean mentioned, we anticipate receiving first silicon devices of Gemini-II in February. After initial evaluation and debugging, we will target a second spin this summer and initiate benchmarking shortly after. Our $2.3 million in SBIR funding will support this development. As a reminder, this includes our recently announced second SBIR Direct-to-Phase II $1.1 million contract to create specialized algorithms for the U.S. Air Force Research Laboratory. The target applications include in-craft applications such as search and rescue, object detection, moving target indication, change detection, and SSIM in GPS-absent situations. GSI will also develop algorithms using data from the U.S. Space Force to showcase the performance benefits of its compute-in-memory APU2 integrated circuit. In summary, the versatility of architecture, hands-on customer engagements, and ecosystem partnerships gives us confidence in our market opportunity. We have a robust product roadmap to deliver continuous innovations that we can -- that we believe will capitalize APU adoption across multiple industries in the coming years. Let me switch now to customer and product breakdown for the third quarter. In the third quarter of fiscal 2024, sales to Nokia were $807,000 or 15.2% of net revenues compared to $1.3 million or 20% of net revenues in the same period a year ago, and $1.2 million or 20.3% of revenues in the prior quarter. Military/defense sales were 28.2% of third quarter shipments compared to 26.2% of shipments in the comparable period a year ago, and 34.8% of shipments in the prior quarter. SigmaQuad sales were 46.9% of third quarter shipments compared to 45.2% in the third quarter of fiscal 2023, and 55.8% in the prior quarter. On one last note on product sales in the third quarter, we shipped over $600,000 of a prototype radiation-hardened SRAM to two different customers. These will be deployed in two separate satellite programs. I'd like to hand the call over to Doug. Doug, go ahead, please.\nDouglas Schirle: Thank you, Didier. We reported a net loss of $6.6 million, or $0.26 per diluted share, on net revenues of $5.3 million for the third quarter of fiscal 2024, compared to net losses of $4.8 million, or $0.20 per diluted share, on net revenues of $6.4 million for the third quarter of fiscal 2023 and a net loss of $4.1 million, or $0.16 per diluted share, on net revenues of $5.7 million in the second quarter of fiscal 2024. Gross margin was 55.9% compared to 57.5% in the prior-year period and 54.7% in the preceding second quarter. The changes in gross margin were primarily due to changes in product mix and volume sold in the three periods. Total operating expenses in the third quarter of fiscal 2024 were $9.7 million compared to $8.5 million in the third quarter of fiscal 2023 and $7.2 million in the prior quarter. Research and development expenses were $7 million compared to $5.5 million in the prior-year period and $4.7 million in the prior quarter. Selling, general and administrative expenses were $2.7 million in the quarter ended December 31, 2023 compared to $3 million in the prior-year quarter and $2.5 million in the previous quarter. Third quarter fiscal 2024 operating loss was $6.7 million compared to $4.8 million in the prior-year period and an operating loss of $4.1 million in the prior quarter. Third quarter fiscal 2024 net loss included net interest and other income of $155,000 and a tax provision of $71,000, compared to net interest and other income of $61,000 and a tax provision of $84,000 for the same period a year ago. In the preceding second quarter, net loss included net interest and other income of $71,000 and a tax provision of $33,000. Total third quarter pre-tax stock-based compensation expense was $649,000 compared to $655,000 in the comparable quarter a year ago and $676,000 in the prior quarter. At December 31, 2023, we had $21.6 million in cash and cash equivalents, compared to $30.6 million in cash, cash equivalents and short-term investments at March 31, 2023. Working capital was $23.1 million as of December 31, 2023 versus $34.7 million at March 31, 2023, with no debt. Stockholders' equity as of December 31 was $39.6 million compared to $51.4 million as of the fiscal year ended March 31, 2023. For the fourth quarter of fiscal 2024, we anticipate net revenues in a range of $4.8 million to $5.4 million, with gross margin of approximately 55% to 57%. Operator, at this point, we'd like to open the call to Q&A.\nOperator: Thank you. We will now be conducting a question-and-answer session. [Operator Instructions] Our first question is from Brett Reiss with Janney Montgomery Scott. Please proceed with your question.\nBrett Reiss: Hi, gentlemen. You can talk to me like I'm six-years-old. Could you just explain what is an infrequent $2.4 million charge for a pre-production mask? I'm not an engineer. Just if you can give me some more clarity on that?\nDouglas Schirle: Yeah. So, every time we have a product, we have to have a mask set prepared to run in the fab to manufacture the wafers. Now, typically, when we incur charges for mask set for production product, we will capitalize that into prepaids and amortize it over a 12-month period. However, the one exception to that is when we have mask set prepared on a new process technology that we've never run before, we'll charge that expense to R&D expense. So, in this quarter -- well last quarter, we taped out Gemini-II on a process technology we've never used. It's a 16-nanometer process at TSMC. Now, since we've never used that process before, we charge that $2.4 million to R&D expense.\nBrett Reiss: All right. So, this is one shot. It's not going to be reoccurring?\nDouglas Schirle: No. It will recur in the future when we have another product that tapes out on a process technology that we've never used before. So, it's infrequent. It doesn't happen every year. It's at most every two or three years.\nBrett Reiss: Okay. The cash, which was my margin of safety in my investment here, keeps dwindling down. I'm a little concerned about that. Some of these initiatives with bringing in other joint venture partners, what's the timetable on that? And how long do we have before we burn through the remaining cash?\nDouglas Schirle: Well, we're currently looking at various opportunities, and Didier mentioned talking to hyperscalers and others. To come out with our next product, it's going to require significant investments, so we're looking for partners or other sources of funding. In addition to that, we have a building that's -- we own that's worth quite a bit of money, and we'll be looking into potentially selling that building in the near future.\nBrett Reiss: Right. What is the building appraised at? And in a base case scenario, what do you think you could sell it for?\nDouglas Schirle: We think we can probably get somewhere in the range of $10 million to $13 million.\nBrett Reiss: Right.\nDouglas Schirle: And there's no debt tied to that. It's fully paid for.\nBrett Reiss: Right. Could you just give me a broad outline of what the structure of a joint venture partner's capital investment in GSIT would take? Would they pay an upfront milestone payment with other payments to follow? Would it be an equity investment? What do you think the structure of that would look like?\nDidier Lasserre: So, it could be either of those. What I mean is when Lee-Lean was talking about a partner for funding the next program, that's specifically for Gemini-III. So, Gemini-II was fully funded internally. But for Gemini-III, we are looking for a partner for that, most likely a customer funding partner. But aside from that, that would be more of an NRE type of funding, so there would be milestones associated with that. But aside from that, we are also open to equity investments in the company as well.\nBrett Reiss: Okay. I'll drop back in queue. Thanks for taking my questions.\nDouglas Schirle: Thank you.\nDidier Lasserre: Thanks, Brett.\nOperator: [Operator Instructions] Our next question is from Jeff Bernstein with Silverberg Bernstein Capital. Please proceed with your question.\nJeff Bernstein: Yeah, hi. Good afternoon. So, just a question on the -- and congratulations on placing those rad-hard SRAM parts for evaluation. If you were to win those programs, about how much revenue and over what time period might you be able to gain from those two satellite programs?\nDidier Lasserre: Sure. So one of the programs was -- and again, this is just a prototype quantity for demonstration purposes. One of them was just over $500,000 and the other one was about $150,000, and it totaled 41 parts that we shipped. You can do quick calculation with the ASPs are on those. And so, those are just the, again, prototype quantities. So, obviously, you can multiply by something. We don't have the quantities yet. These are programs that they're looking to launch within the next year. And so, it would be sometime second half of 2025 at the soonest before they release production. But certainly it would be north -- if the prototype is $500,000, you can imagine what a production might be.\nJeff Bernstein: And so, these would be like GEO satellites. So, these aren't satellite networks. These are going to be individual larger satellites?\nDidier Lasserre: These ones are X, one is GEO, one is actually LEO.\nJeff Bernstein: Okay. And will you get an automatic with these evaluation parts? Are you going to get a ride into space on one of these and actually get sort of provenance from that, or are we still looking to get that somewhere else?\nDidier Lasserre: No. So, certainly, we have -- as we've spoken in the past, we have other prototype devices we've shipped out already in the last couple of years. And so, it could be any of the programs we've said in the past or these two. One of these looks like is fairly accelerated in their timetable. So, there's a chance one of the ones we just shipped this last quarter could get up fairly quickly.\nJeff Bernstein: Okay. And then, just on Nokia lowest revenue from them in forever, what's the story on Nokia and the outlook for that router that you sell into?\nDidier Lasserre: So, they're contract manufacturers, because we send these parts to two separate contract manufacturers. And they both had a little bit of inventory, so they were burning through some inventory. As far as the -- we get, I think we've talked in the past, a 12-month rolling forecast from Nokia, and those still are coming in around the run rate we've been seeing for the last couple quarters. So, just a little bit north of what we did this past quarter, somewhere in $1 million, $1.1 million kind of range a quarter.\nJeff Bernstein: Okay. And at Needham, I think you also mentioned in addition to looking for a partner, potentially a financial partner, potentially a development partner, possibly a hybrid of both of those for Gemini-III. I think you also mentioned something about potentially licensing IP. It sounds like for what would probably be an edge kind of case for semiconductor IP for doing in-memory processing. Can you just talk about that? Would that be sort of an upfront license and then royalty stream, or just give some color around that?\nLee-Lean Shu: Yeah. The IP -- well, we are more focused on the Gemini-III. So, it could be IP or it could be the product development for the customer. So, basically, I think we have -- as we mentioned in the conference call, I mean we made pretty good progress over the quarter. So -- yeah, so we're still working on it.\nOperator: Thank you. There are no further questions at this time. I'd like to hand the call back to Lee-Lean Shu for any closing comments.\nLee-Lean Shu: Thank you all for joining us. We look forward to speaking with you again when we report our fourth quarter and the full year fiscal 2024 results.\nOperator: This concludes today's conference. You may disconnect your lines at this time. Thank you for your participation."
    },
    {
        "symbol": "GSIT",
        "quarter": 2,
        "year": 2024,
        "date": "2023-10-26 20:10:24",
        "content": "Operator: Ladies and gentlemen, thank you for standing by. Welcome to GSI Technology's Second Quarter Fiscal 2024 Results Conference Call. [Operator Instructions]  Before we begin today's call, the company has requested that I read the following safe harbor statement. The matters discussed in this conference call may include forward-looking statements regarding future events and the future performance of GSI Technology that involve risks and uncertainties that could cause actual results to differ materially from those anticipated. These risks and uncertainties are described in the company's Form 10-K filed with the Securities and Exchange Commission.  Additionally, I have also been asked to advise you that this conference call is being recorded today, October 26, 2023, at the request of GSI Technology.  Hosting the call today is Lee-Lean Shu, the company's Chairman, President and Chief Executive Officer. With him are Douglas Schirle, Chief Financial Officer; and Didier Lasserre, Vice President of Sales.  I would now like to turn the conference over to Mr. Shu. Please go ahead, sir. \nLee-Lean Shu : Good afternoon, and thank you for joining us to review our second quarter fiscal 2024 financial results.  I am pleased to share that we have achieved two significant milestones since we reported Q1 2024 earnings. First, was the successful launch of the alpha version of our Copperhead compiler suite, a Python-based tool that can harness the capabilities of the Gemini APU. We anticipate releasing the general release of the Copperhead compiler suite in early 2024. A full production version will be available later in 2024.  Currently, we have partners learning, using and developing algorithms with our compiler, including SWAC, a consortium of universities and the companies developing these generation technology for space and academic research group, exploring the future of computing architecture, like MIT and the University of California, Riverside.  The second milestone was the completion of the Gemini-II tape-out, which were launched last week. As a result, we are on track to have the chip back in our hands early next calendar year as we expect to begin sampling the device in the second half of 2024.  We are targeting Gemini-II partners and customers in low-power data center expansions and enabling data center functions at edge. Example of edge applications could include advanced driver assistance systems and XAG in delivery drone, autonomous robots, unmanned aerial vehicle and satellite.  Turning to our financial results for the second quarter. Revenue of $5.7 million was at the high end of our guidance. Also it's worth noting that our second quarter fiscal year 2023 revenue was boosted by inventory builds with several key customers, which presents a challenging year-over-year comparison.  In addition to advancing the table of Gemini-II, a significant area of recent focus has centered around our ongoing engagement with the key hyperscaler partner. I'm delighted to report that these discussions are making notable progress. To our constructive dialogue with this leading cloud computing provider, we have gained invaluable insights into the precise design specification required for Gemini-III to align with the early requirement.  This collaborated effort has enabled us to charge [indiscernible], while identifying potential partners who can bring the essential financial and engagement -- engineering resource to the table for the successful development, manufacturing and the launch of Gemini-III. The evolution will leverage the conversion of high-bandwidth memory into APU architecture, thereby harness the full potential of in-memory compute advantage.  Now I will hand the call over to Didier, who will discuss our business performance further. Please go ahead, Didier. \nDidier Lasserre: Thank you, Lee-Lean. Following up on the projects I mentioned last quarter, throughout the second quarter of fiscal 2024, our team continued to pursue opportunities with Gemini-I to advance our customer engagements. Currently, GSI has a fast vector search plug-in available that allows cloud vector search users to seamlessly add APU-accelerated search to their major cloud-provided hosted workloads, with minimal latency from GSI's hosted data centers.  This FVS plug-in provides accelerated approximate nearest neighbor search response times, enabling access to a large enterprise service at low power that also meets price points for small- and medium-sized businesses. This will be opening up larger markets for us.  Switching to our SAR opportunities. Due to customer feedback, we have decided to launch or low-powered, highly efficient SAR processing as a SaaS offering, along with, of course, also the on-prem version. We are now engaging to bring that service to market. Moreover, we favorably completed benchmarking on a customer's data set.  One target we are engaged with a start-up building satellites that can provide computational capabilities on satellites and space has identified the Gemini APU as its preferred provider for computing solutions for space. The big differentiator, in addition to low-power performance, is the product's radiation-tolerant feature.  On that note, we will be conducting full radiation tolerant testing on Gemini-I next month. By this, I mean, the full range of tests required for customers considering using Gemini-I in space. One of the applications for that radiation tolerant Gemini-I would be ideally suited for SAR and ATR, which is automatic target recognition, and computing and space to name a few.  This summer, we announced that GSI was awarded an SBIR to contract -- I'm sorry, an SBIR contract to perform a feasibility study to adapt Gemini-II to perform computing at the edge in collaboration with the U.S. Air Force and space force. We are currently working on a second SBIR based on the Gemini-II software development, which is very promising and potentially, a similar financial award as the first win.  We continue to file more SBIR as they bring two key benefits: number one, a source of revenue, and they also create use cases within the U.S. government for future APU opportunities.  Let me switch now to customer and product breakdowns for the second quarter. In the second quarter of fiscal 2024, sales to Nokia were $1.2 million, or 20.3% of net revenues, compared to $1.2 million, or 13.6% of net revenues in the same period a year ago, and $1.9 million, or 33.5% of net revenues in the prior quarter.  Military defense sales were 34.8% of second quarter shipments compared to 22.4% of shipments in the comparable year -- I'm sorry, comparable period a year ago and 33.8% of shipments in the prior quarter. SigmaQuad sales were 55.8% of second quarter shipments compared to 58.1% in the second quarter of fiscal 2023 and 58.6% in the prior quarter.  I would like now to hand the call over to Doug. Go ahead, Doug. \nDouglas Schirle: Thank you, Didier. We reported a net loss of $4.1 million or $0.16 per diluted share on net revenues of $5.7 million for the second quarter of fiscal 2024 compared to a net loss of $3.2 million or $0.13 per diluted share on net revenues of $9 million for the second quarter of fiscal 2023 and a net loss of $5.1 million or $0.21 per diluted share on net revenues of $5.6 million for the first quarter of fiscal '24.  Gross margin was 54.7% compared to 62.6% in the prior year period and 54.9% in the preceding first quarter. The changes in gross margin were primarily due to changes in product mix sold in the three periods. Total operating expenses in the second quarter of fiscal 2024 were $7.2 million compared to $8.8 million in the second quarter of fiscal 2023 and $8.2 million in the prior quarter.  Research and development expenses were $4.7 million compared to $6.4 million in the prior year period and $5.2 million in the prior quarter. Selling, general and administrative expenses were $2.5 million in the quarter ended September 30, 2023, compared to $2.4 million in the prior year quarter and $3 million in the previous quarter.  Second quarter fiscal 2024 operating loss was $4.1 million compared to $3.2 million in the prior year period and $5.1 million in the prior quarter. Second quarter fiscal 2024 net loss included interest and other income of $71,000 and a tax provision of $33,000 compared to interest and other income net of $14,000 and a tax provision of $37,000 for the same period a year ago. In the preceding first quarter, net loss included interest and other income net of $80,000 and a tax provision of $51,000.  Total second quarter pretax stock-based compensation expense was $676,000 compared to $661,000 in the comparable quarter a year ago and $820,000 in the prior quarter. At September 30, 2023, the company had $25.3 million in cash, cash equivalents and short-term investments compared to $30.6 million in cash, cash equivalents and short-term investments March 31, 2023. Working capital was $28.8 million as of September 30, 2023, versus $34.7 million at March 31, 2023, with no debt. Stockholders' equity as of September 30, 2023, was $45.4 million compared to $51.4 million as of the fiscal year ended March 31, 2023.  Given the current global economic environment, our current expectations for the upcoming third quarter are net revenues in the range of $5.4 million to $6.2 million, with gross margin of approximately 55% to 57%.  Operator, at this point, we would like to open the call to Q&A. \nOperator: [Operator Instructions] Our first question comes from Brett Reiss with Janney Montgomery Scott. \nBrett Reiss : Until corporate initiatives gain traction, how -- can you just comment on cash burn rates? How long do you think the cash will last without you having to do some sort of financing? \nDouglas Schirle: Yes. We've taken a look at that. We typically take a look at it every quarter. And if nothing improves, which we don't expect, we have cash that should last at least a couple of years at this point. \nBrett Reiss : And if I may just follow up, what do you think your burn will be for this following year? \nDouglas Schirle : This year we'll be around $13 million to $14 million. Yes, we have one kind of extraordinary expense coming up this fiscal year that requires about $2.4 million cash outlay. And that's for the mask set for the Gemini-II product that just taped out that Lee-Lean previously mentioned today. That's somewhat of an irregular occurrence that only happens every few years. \nOperator: [Operator Instructions] Our next question comes from the line of Orin Hirschman with AIGH Investment Partners. \nOrin Hirschman : Can you can you give us a little bit more color on -- is the data center customer interested in Gemini-II for any purpose or only Gemini-III? Have they played with Gemini-I to understand it better? And what is attracting them to the Gemini architecture? And I have one follow-up. \nDidier Lasserre : Okay. So let me start with that. So with the hyperscaler, we're engaged with. And we've had when -- we've had ongoing discussions with, and we've since opened up other discussions with other hyperscalers.  Certainly, as Lee-Lean mentioned in his earlier comments, the information we gathered from our first engagement was instrumental to be able to sharp our story and our offering for future hyperscale conversations. And so what they're -- interested right now would be a next-generation, specifically, something we'll call Gemini-III for now. Because that one is going to really be geared towards GenAI or the LLM models.  With that said, as you know, these hyperscalers are very large companies. And so certainly, Gemini-II is certainly not out of play with them, it just wouldn't be the solution specifically for the GenAI conversations we're having. \nOrin Hirschman : And in terms of other hyperscalers and data center customers, it sounds like there's some level of progress. How would you characterize it? Have people played with benchmarks yet for any of them? I think would be an important point to note if it's true if you've gotten that far. \nDidier Lasserre : Correct. And so what we've done is we've shown obviously the technology with Gemini-I because silicon is here. Software is here. We can run true benchmarks. We've then obviously run expected benchmarks off of Gemini-II.  And so going back, and I just remember what part of your earlier question was, what's interesting about our technology to them? So there's certainly a few areas. Obviously, the performance is important to them. But the low power has certainly grabbed their eye. And also other features like the fact that we're a bit processor. This is very important to a lot of these folks because right now, if they're using a GPU, they're really locked into -- depending on the GPU 8-bit or 16-bit, 32-bit or 64-bit kind of traffic patterns.  We're a bit processor. And so we don't care what your traffic looks like. It can be 4 bit. It can be 64 bit. It can be -- make up a number of 1,000 bit, and we can adapt to that on the fly and cycle to cycle. And so that flexibility is also very important to them. \nOrin Hirschman : In real life, there's been a lot of talk about a very bit type of super processor in the literature. And obviously, no one's really had one commercially where it's programmable in that fashion. Are you programmable today in that fashion, number one. Number two, is what are some of the applications where that becomes so enticing? \nDidier Lasserre : So you're talking about the bit processing? \nOrin Hirschman : Yes. \nDidier Lasserre : Yes. So there's a lot of research going on right now. And they're finding out that some efficiencies aren't coming in like the expected 16-bit and 32-bit. As I mentioned, 5-bit was one that came up recently. And candidly, I don't remember the exact application or the research on that.  But 5 bit was one of them that was important. And so one of the benefits with this bit processing is that as our customers told us, we're future-proof. And what I mean is if there's an application that comes in that needs 5 bit, we're there. If there's one that needs 128-bit, 256 bit, we're there. We don't have to redesign our part to be able to address those needs because of the fact that we have 2 million bit processors on our Gemini-I. And they can work, as I mentioned, as 1 bit or make up a number between 1 million and 2 million. And so we're future-proof from that respect, which is obviously eye opening to them. \nLee-Lean Shu : Yes. Just to comment. Right now, the GenAI, the large language model, is a very big model. It's a very, very memory-intensive application. So they will lead to a big memory. They will lead to very fast memory. So the effort -- one of the effort is they try to reduce the data format, if you have less number of bit to calculate, then you got less memory, you require less memory too.  Okay. So we have big processing capability, which you can -- just like Didier mentioned 5 bit, 4 bit, 3 bit, 2 bit, we will be there. And with this is we have more capability to keep up with the software innovation and that's what some of the customer likes about this issue. \nOrin Hirschman : And just going back to benchmarking, have you done benchmarking for some of the data center and hyperscaler customers? \nDidier Lasserre : So candidly, most of the benchmarking we've done have been based essentially off of POCs, where customers have come in and said, \"This is what I'm using. Here's my data set. What do your numbers look like?\" And so we've done real life case POCs. We've done that for one of our Israeli customers that we talked about and then also one of our recent SAR customers.  As far as broad market benchmarking, we haven't done a lot, but we know that's critical and that's something that's on our agenda to start doing. It's just been a resource issue for us to be able to make that happen. But we understand it's important, and that's what we're next on the list. \nOrin Hirschman : And I see. Two more questions, if I may, and then I'll let other people ask. So in terms of proof of concept using customer data, have any of the hyperscalers given you data sets to actually show them what you can and can't do with it? \nDidier Lasserre : No. These are other applications. These have been SAR applications and other applications. The hyperscalers know. Because as I mentioned, the discussions early on have been revolving around this next-generation device. And so we've given them -- we have given the benchmarking what we anticipate we could do, absolutely, but they're not true benchmarks, they're calculated benchmarking. \nOrin Hirschman : Okay. And last question, just on the you mentioned as you're using the Process-as-a-Service for the people's data, and you had some early tests going back a while ago and that, that needed to be revamped or some additional APIs. Where are you up to with any of the potential customers offering it as a plug-in or anything like that? \nDidier Lasserre : Yes. So there's two areas that we're focusing the SaaS on, fast vector search and SAR. And as I mentioned in my comments earlier, the SAR was after discussions with one of the folks that we're talking to in that area.  So we have an on-prem solution, which for some of their customers, is needed. And then obviously, one of the guys we're talking to you wants to put this capability on the satellite. So that would be a physical sale as well. But right now, most of their production they're doing is via SaaS over AWS using GPU instances. And so that's when we -- after discussing with them, that's something that we looked at. And so that obviously makes sense for us to do.  So we're opening up the SAR for that. The fast vector search we've been putting in place, we're still doing some benchmarking internally for some of the factor search and databases, guys like v8. And so that's an ongoing project for us. \nOrin Hirschman : In terms of trying to get that fast factor searches a plug-in so that customers could actually play with it through AWS or something like that. Any progress there? \nDidier Lasserre : There is -- I'm trying to understand what I can see there. So we've had some discussions recently with a very large data center company to basically integrate easier into their system right now. And so those discussions have been happening over the last couple of weeks.  And then certainly, once those get worked out, then we'll be able to have a smoother offering right now. Because as you know, right now, it's -- we're basically -- they're offloading the searches off to our data center that we have put into a facility called CoreSite. And so we're trying to streamline that offering. \nOperator: [Operator Instructions] Our next question comes from the line Luke Benett, an investor. \nUnidentified Analyst: To zoom out from parsing applications and the prospects for various partnerships, could we assume that when Gemini-I hits the scene and you all are able to offer that to be tooled by various users, will that outperform a large swath of the current high-performance computer offerings that are on the market, including the leaders of NVIDIA, AMD, Samsung, even Google, custom chips. Is that safe to say? \nDidier Lasserre : So -- okay, so I'm trying to follow your question here. So first of all, we do have Gemini-I already. So I'm assuming you were referring to Gemini-II. \nOrin Hirschman : Gemini-II, correct. Yes.\nDidier Lasserre : Yes. And so Gemini-II, and then you also mentioned a custom chip. So Gemini-II is not a custom chip. So Gemini-II is going to be a standard offering that we're going to have. And so yes, obviously, we've done some calculated benchmarkings, which have looked very favorable. And once we have the chip in hand, as Lee-Lean said, we'll have it in hand early next year, and it's probably going to take at least the spend to really get something we can do benchmarking. So it will be around summertime before we can do true benchmarking.  But yes, we anticipate them to be very favorable over what we have and what's in the market space. Now -- but I do want to add to the comment, you said custom chip. So one of the things -- and we've mentioned this in the past, that we're also looking to do is obviously offer IP sales as well, because we do understand we have a unique technology.  But we also understand that certainly, we'll start with the hyperscalers. They do a lot of their own custom silicon. And so one of the conversations that we're having with the hyperscalers besides talking about Gemini-III for the GenAI is we're also talking about IP sales as well for any custom basis that they're doing on their own. So you asked a lot of questions in there. I'm hoping I hit all the topics. \nDouglas Schirle : Yes, that does kind of answer the two implications there. That Gemini-2 will be a compelling competitor and depending on how you're able to benchmark or how much tooling and rendering it requires to via IP or via that chip directly, but that it will.  Yes, essentially, at 16-nanometers, the competing toe-to-toe or you mean clearly out competing in a lot of these 5-nanometer leading high-performance chips. \nDidier Lasserre : If you recall, Gemini-I, the benchmarking we've done in the past have been very positive against what's out there today. Now with Gemini-II, as we discussed in the past, it has 10x of performance and 8x the L1 memory on chip. So it's certainly going to be something that's going to be very compelling for the market. \nOperator: Our next question comes from George Gasper, an investor. \nUnidentified Analyst: Could you go into a little additional information for us on the military and defense applications and the interconnect that the company has had in Israel over the years, in fact, initially the whole Gemini approach came out of there? And considering what's going on in space, is there broader applications for the advancements that you're making going into space? And is what's happening with Israel right now in terms of this situation in the Middle East. Is there -- are you seeing anything happen that could create a more military-related effort? \nDidier Lasserre : Okay. So I'm going to try and get all those questions now. So let's start with the military. So yes, there are a lot of different possible use cases with the military, which is also why we've had some successes recently with these SBIR that we've been filing.  So some of the interest that we've seen have -- from like we'll call the mill arrow kind of area is certainly SAR for sure. Object detection, is another automatic target recognition, another. We've also been for imaging as well for change detection. Just -- and also one of the customers that we're engaged with, in fact, they have two of our servers on loan that they're doing demonstrations with is they want to start putting data centers in space.  And so that's another -- just a standard data center application in space. And so that's another one. As far as I'm not sure what the Israel site. So as you say, this original technology was an acquisition we made, and the company was out of Israel. But I'm not sure what the question was revolving around that acquisition. \nUnidentified Analyst: Well, basically, just as a reference, I mentioned it. But considering what's going on in the Middle East right now and the connections that the company has had with Israel, I would think that there would be an attempt to try to get some applications moving forward to -- give Israel a more recognition in how they're trying to monitor things. Is that…?\nDidier Lasserre : Yes. So we've had some discussions, obviously, with fat that we've talked about in the past and other entities there on several applications. I won't go to exact detail, but there's certainly -- I'm sure we'll -- there will -- certain areas that we've talked about with them will, most likely get accelerated now because of obviously what's happening now. But right now, we're not having those discussions right now. There's more pressing issues in Israel right now. \nUnidentified Analyst: I see. Okay. Well, it looks like you're about to make some generally movements forward with Gemini-II going to III. Hopefully, this really starts to turn the company around in terms of its revenue volume and would expect that by the end of this fiscal year. There's some real momentum going forward. Can you comment on it? \nDidier Lasserre : Yes. There's certainly momentum. And as time goes on, we hope to announce more traction. But the end of the fiscal year, any revenue that comes will be coming from Gemini-I. So as we've discussed, Gemini-II, we're not going to be even sampling it until summer of next year. And so that falls into fiscal '25. \nOperator: As there are no further questions, I would now hand the conference over to the management for their closing remarks. \nLee-Lean Shu : Thank you all for joining us. We look forward to speaking with you again when we report our third quarter fiscal 2024 results. Thanks.\nOperator: Thank you. The conference of GSI Technology has now concluded. Thank you for your participation. You may now disconnect your lines."
    },
    {
        "symbol": "GSIT",
        "quarter": 1,
        "year": 2024,
        "date": "2023-07-27 22:57:04",
        "content": "Operator: Ladies and gentlemen, thank you for standing by. Welcome to GSI Technology's First Quarter Fiscal 2024 Results Conference Call. At this time, all participants are in listen-only mode. Later, we will conduct a question-and-answer session. At that time, we will provide instruction for those interested in entering the queue for the Q&A. Before we begin today's calls, the company has requested that I read the following Safe Harbor statement. The matters discussed in this conference call may include forward-looking statements regarding future events and the future performance of GSI Technology that involves risks and uncertainties that could cause actual results to differ materially from those anticipated. These risks and uncertainties are described in the company Form 10-K filed with the Securities and Exchange Commission. Additionally, I have also been asked to advise you that this conference call is being recorded today, July 27, 2023 at the request of GSI Technology. Hosting the call today is Lee-Lean Shu, the company's Chairman, President and Chief Executive Officer. With him are Douglas Schirle, Chief Financial Officer; and Didier Lasserre, Vice President of Sales. I would like now to turn the conference over to Mr. Shu. Please go ahead, sir.\nLee-Lean Shu: Good day, everyone. And welcome to our first quarter fiscal year 2024 earnings call. We are happy to update you on our achievement of milestones on our journey to innovation and growth. Our dedication and focus have allowed us to make good progress during our first quarter of fiscal of 2024. Let's start with our progress on the fencing our growth in innovation objective. And now with our commitment to lend Gemini-I customer, we have to move forward to the demo with two of our soft targets. Additionally, we add new resource to address the fast vector search market at home our product for this application. Didier will provide more color on this in his comments. Additionally, I'm pleased to share that Version 2 of our L-Python compiler stack is on track for release to beta customers by the end of this summer. This marks a significant step following our product roadmap, enabling us to deliver cutting edge solutions into our customer satisfaction. Your pattern is designed to make it easy for other developers to contribute and improve the software. The appeal of L-Python is that it can be used on different operating systems like Windows, Linux, and Mac OS. The reason L-Python is so fast it's, because it performs optimization at both at high level and the low level. This means it try to make the code more efficient before running it. Additionally, L-Python allow for easy customization of the different ways you can convert the code which can be useful for specific days or preference. Not only is L-Python fast and refreshable, but the stack is also usable for other applications. We believe we could readily create the ecosystem beyond the APU. We are closing in on successfully completing the table of Gemini-II [indiscernible] to be finalize and send off to TSMC in the next few weeks. This cave art is a major achievement and to showcase our commitment to push the boundaries of AI chip technology. [Indiscernible] tool is extremely [indiscernible] and the successful completion of this master serves us a testimony to our talented teams hard work and equities. We anticipate centering the solution during the second half of calendar year 2024. We remain focused on driving innovation, delivering exceptional products and leveraging those trends to faster strategic partnership that will help propel our company forward. The strategic addition to our team reinforce our commitment to drive growth, faster in partnership and deliver innovated solution to our customer. We are excited about our opportunities, and the value and individuals who will bring to our organization as they work with our dedicated team to position us for success. I have understand our employees, customers and shareholders for their unwavering support and commitment. Together, we will continue to build a brighter future for our company. Now, I will hand the call over to Didier who will discuss operating development and sales activities. Please go ahead, Didier.\nDidier Lasserre: Thank you, Lee-Lean. I want to start by addressing a point mentioned earlier by Lee-Lean, we have strengthened our team with the addition of two highly skilled professionals who will play pivotal roles in developing strategic partnerships with hyperscalers and establishing our presence in the fast vector search market. These individuals bring a wealth of knowledge and extensive experience in their respective fields. One of our new team members, who will assume the senior data scientist role will lead our team on various projects and offload some of the workload from our division in Israel. With this team, we will transfer some functions to the U.S., including developing software applications, functions, and undertaking government related projects that require collaboration with U.S. based employees. Our U.S. data science team will play a crucial role in assisting customers with the compiler and conducting benchmarks across different platforms. Our new data scientists will collaborate with this team to optimize our plugin for fast vector search, paving the way for the successful deployment of this business line for our company. Our second new resource brings a wealth of experience from the semiconductor sector, having worked for the leading FPGA companies. This background has afforded him extensive industry connections which will be invaluable as we strive to engage and form partnerships with our top hyperscalers. We will lead the building of our platform - I'm sorry, he will lead the building of our platform to explore strategic partners for our APU technology to develop service and licensing revenue resources to fund future APU development. On the last call, we mentioned we were working with a major hyperscaler based on Gemini architecture for inference of large language models. This relationship holds great potential for our growth. And we recently added additional resources to this team. We have conducted a feasibility study exploring Gemini architecture. And I am delighted to say that we are making great progress in this prospect. The study is specifically focuses on GPT inference utilizing a future APU. We found that the APU when compared to existing technologies can achieve significantly enhanced performance levels while utilizing the same process technology. GPT is a memory intensive application, it requires a very large and very fast memory hierarchy from external storage memory all the way to the internal processors working memory. And the GPT 175 billion model, 175 gigabyte of fast memory is required to store the models parameters. This can be accomplished by incorporating a processor die and several HBM, which are high bandwidth memories. And we'll be put on a 2.5 d substrate. It also requires large internal memory and very fast internal memory next to the processor core as a working memory to support the large matrix multiplication performed by the processor core. APU architecture has inherently large built in memory and large memory bandwidth that not only provides memory throughput, but also supports very high performance computation. Gemini can achieve similar peak tops per watt as state-of-the-art GPUs on the same process technology node. However, with our massive L1 size and large bandwidth, the APU can sustain average tops nearly the same as peak tops unlike a GPU. And a single module composed of a 5-nanometer Gemini dye plus six HBM three dye we have calculated that we could achieve more than point six token per second per watt, with the input size of 32 tokens to generate a context of 64 tokens in GPT 175 billion model. This output is more than 60 times the performance that could be delivered by a state-of-the-art GPU and a slightly better technology node. The study was done in conjunction with laying out the development roadmap for Gemini III to move further into generative AI territory. The APU holds a distinctive advantage in delivering low power consumption at peak performance levels, given the in memory processing capability. As we have seen, generative AI applications like ChatGPT, are becoming more capable with each generation. The driving force behind this improvement capability is the number of parameters used by the large language model that power them. More parameters require more computation, leading to higher energy usage and a much larger carbon footprint. To help combat the carbon footprint growth, researchers are exploring new ways to compress data to reduce memory requirements. These are trade-offs between the format's that researchers are investigating. To navigate these trade-offs they need a flexible solution. Unfortunately, GPUs and CPUs lack this flexibility and are limited to a small fixed set of data formats. GSI Technology's, APU technology provides the flexibility to explore new methods. By allowing computation to be performed at the bid level computation can be performed on any size data element with a resolution as fine as a single bit. This will allow innovative solutions to be developed. And we reduce energy by optimizing the number of usable bits for each data transfer. As we work with potential strategic licensing partners, we can increase the awareness of our capabilities to solve some of AI's biggest challenges. Regarding our work on Gemini I solution, we have made notable progress with two of our SAR targets. Underscoring our commitment to expanding our presence in this market, we have set a goal of closing a sale in FY 2024 with one of these customers. As I mentioned, we recently added resources to support our beta fast vector search customers. With additional resources in place we anticipate building a SaaS revenue source with customized solution for fast vector search customers before the end of the fiscal year. Let me switch now to the customer and product breakdown for the first quarter. In the first quarter of fiscal 2024. Sales to new Kia were $1.9 million or 33% of net revenues compared to $1.3 million or 14% of net revenues in the same period a year ago, and $1.2 million or 21.8% of net revenues in the prior quarter. Military defense sales were 33.8% of first quarter shipments compared to 22.3% of shipments in the comparable period a year ago and 44.2% of shipments in the prior quarter. SigmaQuad sales were 58.6% of first quarter shipments compared to 44.8% in the first quarter of fiscal 2023 and 46.3% in the prior quarter. I now like to hand the call over to Doug. Please go ahead. Doug?\nDouglas Schirle: Thank you, Didier. GSI reported a net loss of $5.1 million or $0.21 per diluted share on net revenues of $5.6 million for the first quarter of fiscal 2024 compared to a net loss of $4 million, or $0.16 per diluted share on net revenues of $8.9 million for the first quarter of fiscal 2023 and a net loss of $4 million or $0.16 per diluted share on net revenues of $5.4 million for the fourth quarter fiscal 2023. Gross margin was 54.9% in the first quarter of fiscal 2024 compared to 60.2% in the prior year period, and 55.9% in the preceding fourth quarter. The year-on-year decrease in gross margin in the first quarter of fiscal 2024 was primarily due to the impact of fixed manufacturing costs and our cost of goods on lower net revenue. Total operating expenses in the first quarter of fiscal 2024 were $8.2 million, compared to $9.3 million in the first quarter of fiscal 2023 and $6.9 million in the prior quarter. Research and Development expenses were $5.2 million compared to $6.6 million in the prior year period and $5 million in the prior quarter. Selling, general and administrative expenses were $3 million in the quarter ended June 30, 2023 compared $2.7 million in the prior year quarter and $1.9 million in the previous quarter. We estimate that through June 30, 2023. We have incurred research and development, spending in excess of $140 million on our AP product offering. First quarter fiscal 2024, operating loss was $5.1 million, compared to an operating loss of $3.9 million in the prior year period, and an operating loss of $3.9 million in the prior quarter. First quarter fiscal 2024, net loss included interest and other income of $80,000 and a tax provision of $51,000 compared to $26,000 in interest, other expense and a tax provision of $60,000 for the same period a year ago. In the preceding fourth quarter, net loss included interest and other income of $101,000 and a tax provision of $191,000. Total first quarter pretax stock- based compensation expense was $820,000 compared to $638,000 in the comparable quarter a year ago, and $515,000 in the prior quarter. At June 30, 2023, the company had $27.7 million in cash, cash equivalents and short-term investments, compared to $30.6 million dollars in cash, cash equivalents and short-term investments at March 31, 2023. Working capital is $32.1 million as of June 30, 2023, compared to $34.7 million at March 31, 2023 with no debt. Stockholders' equity as of June 30, 2023, was $48.6 million, compared to $51.4 million as of the fiscal year ended March 31 2023. During the June quarter, the company filed a registration statement on Form S-3 so that the company would be in a position to quickly access the markets and raise capital if the opportunity arises. Operator at this point, we'll open up for Q&A.\nOperator: Thank you. [Operator Instructions] Our first question comes from Nick Doyle, Needham and Company. Please sir, go ahead.\nNick Doyle: Nick Doyle from Needham. Thanks for taking my questions. Just first, could you expand on the drivers behind gross margin this quarter and next quarter? So, we could see a little bit of a decline this quarter and you're expected to increase next quarter? Could you just expand on why that's happening?\nDouglas Schirle: Yes, it's really related to product mix. We do our best effort at forecasting what we believe that revenues are going to be during the quarter. But obviously with only about a third or so of the quarter booked at the beginning in the quarter, we have to estimate where the revenues are going to come from. It is strictly tied up to product mix nothing more.\nNick Doyle: Okay. Could you just tell us, what part of the mix was higher this quarter that's driving the lower margin?\nDouglas Schirle: Yes, the biggest thing that impacts the margin is that we have quite a bit of military business and that has the highest margin. Alcatel Lucent revenues are - sorry, Nokia revenues are generally at a reasonable level and that also was good margin. So it really is dependent on probably the biggest factors military sales at this point.\nNick Doyle: Okay. Great. Makes sense. So you talked about, how you tested your APU which can basically sustain higher tops and drive better performance per watt with this specific GPT application. Can you just expand on how that's done how your APU differentiates from CPUs and GPUs on the market? Is it entirely to do with the ability to do computations at the bit level? That was my understanding, yes any detail there will be great?\nLee-Lean Shu: Yes, first of all, key few has a very, very small cash. And I think is a good for the graphic processing. But when you talk about the future, future parameter a larger language model, they can only do a fraction of what they can do, from the top point of view. And in the GPU, we have a huge, huge memory inside the chip. And we calculate the top, and particularly from the - how we can support the processing with our memory. Okay. That's how we come out with the top. So that's why we have able to top or spend or pick top. Okay. So, I hope I answered your question?\nNick Doyle: Okay. I know I can sneak one more. I think in the past, you talked about the cost of Gemini II is about $2.5 million. Is that still the case? And is that entire tape out costs behind us or it's still ongoing?\nLee-Lean Shu: [indiscernible].\nDouglas Schirle: Yes, $2.5 million is a tape out cost. So, we will have a tape out, the expense could hit later this quarter or early part of the October quarter. But yes, that's just the tape out quarter. We've incurred as we said in our comments, probably in excess of about $140 million developing this product line. And that's what you want in G-II.\nNick Doyle: Great. Thanks.\nLee-Lean Shu: Just one comment, we published a white paper on our website. And we have a further discussion on you know why APU is a good for the larger language model. So, if you are interested look at www.gsitechnology.com.\nOperator: [Operator Instructions] Our next question comes from Luke Bohn, Private Investor. Please sir, go ahead.\nUnidentified Analyst: Thanks. So, in terms of the study, could you mentioned that that was projecting a 5-nanometer architecture yes for the - study about comparing with GPUs and peak performance? I supposing based on your understanding of the engineering the physics of your APU architecture that you project that is feasible, and is that the case? And can you project even further to say that yes, there is a limit that's lower than in terms of reducing to get even more dense net and more dense architecture?\nLee-Lean Shu: Yes, we peak phenomenon because at this moment, the sale of our processor is either .5 or 4-nanometer. So, we want to have you know, apple-to-apple comparison. So we pick nanometer as a study base. Of course, if we want to implement a real chip, I think we want to do it with even more advanced technology. So adjusting with everybody else.\nUnidentified Analyst: Okay. Yes. So that is the tentative plan is to make the lead basically from your current I think you said 16. Gemini II all the way to the 5 and for Gemini III?\nLee-Lean Shu: Yes. No, no I'm sorry. Gemini III is to be determined. We pick 5-nanometer just, because everybody else is on the 5-nanometer. So it's fair comparison.\nDidier Lasserre: Right. So - just for comparison for the study, because that's what as Lee-Lean just said, that's what the GPUs are on as 5-nanometer. So, we wanted to do a straight comparison on technology. That does not mean Gemini-III wouldn't be on that technology, it could be something more aggressive.\nUnidentified Analyst: Okay, yes. It's not a limit point.\nDidier Lasserre: Correct.\nUnidentified Analyst: Excellent. And in terms of the - you all having larger memory cache, and all the other advantages of flexibility in the memory that I read about in the white paper. How does that apply to comparing the APU to GPUs in machine vision for the fact like real world vision, talking about EVs, autonomous vehicles and kind of referencing the Tesla earnings call saying that they're buying as many NVIDIA GPUs as they can get their hands on. And you also lay references of being able to apply the APU to that market, as well as yes more of the more abstract machine vision, drug discovery and genetic medicine, things like that. Are you seeing still similar yes, advantages?\nDidier Lasserre: Yes, so I mean, the advantage, yes, the answer is, you know, our Gemini I we understood was not a fit for what you talked about ADAS. Gemini II, we anticipate to be a better fit, just because of the lack of an FPGA on the board with the gym. But the fundamental unique architecture is going to be the same, which is the fact that, you know, we're doing the computation or the search on the memory bit line in place. And so, we're not going off chip to fetch the data, and then going back and rewriting the data. So that's, the fundamental, unique architecture that we have is in regardless of the market, and is available or there with Gemini I and Gemini II.\nUnidentified Analyst: Awesome. Yes, this one's yes, get that clarification about because since, yes even talked about the performance being kind of Orford GPUs being apt for visual processing. So I wonder yes I get that clarification about the more, broader kind of machine vision, visual processing markets there. Yes, that's great. I think I have one more question. Yes definitely applaud you all for getting moving forward with yes the SaaS and vector search, because there have been so many announcements recently about the value of large vector search NLP, neural networks broadly, and seeing how much of that TAM, you all can address? Yes, definitely get there yes the shade you're putting just more traction to that pathway. And I want just kind of funny curiosity, I've noticed the name Gemini associated with accelerated computing, most recently, most prominently with Google. And it always made sense to me in terms of parallel processing. You have the name Gemini, and historical reference. But wondering, yes spin Q and Google, have not also adopted Gemini and wondering if that is at all an encroachment on your intellectual or your trademark? Or if you find that to just be a kind of a humorous affirmation. Since you're the first Gemini?\nDidier Lasserre: No, we definitely looked into it. And the issue we have is that our trademark is for hardware devices, semiconductor device, and Google is software related. So there's no overlapping.\nUnidentified Analyst: Okay, that makes sense. Okay, so is there anything shifted? I'm not sure if you've actually crunched numbers, but in terms of you have your TAM. And you have SAM, and these new focuses on the large language models? Yes, how do you see kind of the concrete bigger, concrete addressable market projections updated at this point in terms of timeline and, and size?\nDidier Lasserre: Yes, so we're still working on those TAMs for that, and you know, and there's different segments, right? You have the retrieval and you have the generative. And so, those are two different areas. And we can certainly address the retrieval now with Gemini I and Gemini II, we certainly feel for the generative side, it's going to be more of a Gemini III. But yes, we're working on those TAMs, SAMs now. They're just not available yet.\nUnidentified Analyst: Yes, yes. I know it's a hard thing to value which is reflected in yes all over the analyst side of things. Yes that's, I think that's all I've got. Thank you.\nDidier Lasserre: Thank you, Luke.\nOperator: Our next question came from Jeff Bernstein, TD Cowen. Please sir, go ahead.\nJeff Bernstein: Yes, hi, guys. Couple questions for you. One just on that the last answer. You were talking about Gemini I and Gemini II, addressing retrieval. So you mean queries there? And when you say addressing generative are you talking about training or just clarify that a little bit?\nDidier Lasserre: The response, right. So yes, so you're retrieving the data. And that's something we do very well now, but it's really generating the response. And so that requires very, very high memory bandwidth, which we have in very, very high memory cache in general. I mean that's why we talked about pairing up with HBM III for that. And so that's, and that's more on the generative side.\nJeff Bernstein: Okay, so training?\nLee-Lean Shu: No, no inference.\nDidier Lasserre: It's to inference, yes. It's not training.\nJeff Bernstein: Okay, still inference. Okay. And then as long as you were talking about the potential for a 5-nanometer or more aggressive, kind of Gemini III, line with, what is the current tape out cost? I know that you're not a processor, more like a memory. So it might be less expensive. But what do you think a tape out cost of 5-nanometer would be now?\nLee-Lean Shu: 5-nanometer the mass costs itself about $15 million, one five to have a design like 5-nanometer, we probably need to have $100 million for the design. So what we are doing right now is we are looking for the partner. We are not planning to do it ourselves so.\nJeff Bernstein: Yes. Okay. And then I just want to talk about the capital situation. You've now got a registration statement in place. Unfortunately, you missed the big run up in the stock. Why wouldn't you preferentially sell and lease back the headquarters for funds, and then have some more tangible progress to show? Before we started talking about raising equity?\nDidier Lasserre: Well, we have looked into the sale of the building, and we haven't decided to do that yet. But that still is an option. You know, property values are certainly higher than we purchase a building, many years ago. And it is an opportunity that we have considered and we've discussed it with the Board, but no decision as of yet has been made to sell the building.\nJeff Bernstein: Got you. Okay. And then just on the Nokia business that if I remember correctly, you guys were in. Now at this point they pretty old Nokia 7970 and 7950 routers. I don't even see any reference anymore to the 50. What's going on there? How much lead time would you get? If they were and licensing that? Would there be some kind of lucrative and life you know, revenue that you might get out of that et cetera? Just give us a little feeling for your understanding of where you are with the Nokia business?\nDidier Lasserre: Sure, yes. So as you said as CEO in the 7750, and 7950 platforms there, and they have extremely long life cycles as we've been seeing, we get a 12 month rolling forecast from Nokia. And so far, and that's as far as they go and the 12 months still looks healthy. What they did do a while back, is they did what's called a midlife kicker, to try and give a little bit more performance to those existing systems. And what that meant for us is that it went from a 72 megabit density into a 144 megabit density part for that midlife kicker. And so the ASPs are obviously higher on the larger density part. So what we saw is, even though some of the volumes have come down over time, it's been fairly flat on the revenue side, just because the increase in the ASPs offset the decrease in the quantity. So at this point, it's still going we still have the 12-month forecast it looks healthy, and that's as much visibility as we get.\nJeff Bernstein: Got you. And then obviously, there is movement around the chip shortages and packaging shortages and that kind of thing. Are we now to a more normalized rate here going forward?\nDidier Lasserre: So, the lead times have become more normalized, the pricing or the costs have not. So the price increases that that were subjected to us, which in turn, forced us to raise prices to our customers. They're still there. And so we've kept our ASPs up, and we'll keep them there until there's any kind of movement from TSMC or any of the substrate folks that raise their prices. But at this point, the real change is the lead time, lead times have come down to a more normalized area.\nJeff Bernstein: Got you. But just in terms of inventories, we should be at a more normal kind of inventory situation going forward here?\nDouglas Schirle: Yes, that's what we fully believe in. And our inventories have dropped the last quarter to, and we expect them to drop the next couple of quarters or so.\nJeff Bernstein: Right. Thank you.\nOperator: One moment, please, while we poll for questions. Our next question comes from George Gaspar, Private Investor. Please sir, go ahead.\nUnidentified Analyst: Thank you. It's George Gasper. Just again, I'd like to do on the financing situation based on your current cash position. And looking at your current development progress profile. What do you see, is your forward view and the need to exercise financing requirement?\nDouglas Schirle: Well, at this point, given the materials we've discussed with the Board that, this fiscal year will certainly burn some cash and maybe $12 million to $13 million. If the revenue numbers hold up. And if the revenue numbers hold up next year, we could start turning the corner and actually having more cash at the end of fiscal 2025 than at the end of fiscal '24.\nUnidentified Analyst: I see. So what you're saying is that - based on the way you're moving along, at your present cash position is sufficient for what you're talking - what your targets are and the development that you see over the next year?\nDouglas Schirle: Currently, that's true. That's a situation.\nUnidentified Analyst: That is okay. All right. Thank you. Thank you.\nOperator: Thank you. There is no further question at the time. I'd like now to turn the floor back over to Mr. Chu, for close for closing comments. Please, sir, go ahead.\nLee-Lean Shu: Thank you all for joining us. We look forward to speaking with you again when we report our second quarter fiscal 2024. Thank you.\nOperator: This concludes today's teleconference. You may disconnect your lines at this time. Thank you for your participation."
    }
]