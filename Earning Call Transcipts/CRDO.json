[
    {
        "symbol": "CRDO",
        "quarter": 3,
        "year": 2024,
        "date": "2024-02-27 23:23:14",
        "content": "Operator: Good day, and thank you for standing by. Welcome to the Credo Fiscal 2024 Q3 Earnings Conference Call. [Operator Instructions] Please be advised that today's conference is being recorded. I would now like to hand the conference over to your speaker today, Dan O'Neil. Please go ahead.\nDan O'Neil: Good afternoon. Thank you for joining us on our Fiscal 2024 third quarter earnings call. Today, I'm joined by Bill Brennan, Credo's Chief Executive Officer, and Dan Fleming, our Chief Financial Officer. As a reminder, during the call, we will make certain forward-looking statements. These forward-looking statements are subject to risks and uncertainties that are discussed in detail in documents filed with the SEC, which can be found in the Investor relations section of the Company's website. It's not possible for the Company's management to predict all risks, nor can the Company assess the impact of all factors on its business or the extent to which any factor or combination of factors may cause actual results to differ materially from those contained in any forward-looking statement. Given these risks, uncertainties and assumptions, the forward-looking events discussed during this call may not occur and actual results could differ materially and adversely from those anticipated or implied. The Company undertakes no obligation to publicly update forward-looking statements for any reason after the date of this call to conform these statements to actual results or to changes in the Company's expectations, except as required by law. Also, during this call, we will refer to certain non-GAAP financial measures which we consider to be important measures of the Company's performance. These non-GAAP financial measures are provided in addition to, and not as a substitute for or superior to, financial performance prepared in accordance with U.S. GAAP. A discussion of why we use non-GAAP financial measures and reconciliations between our GAAP and non-GAAP financial measures is available in the earnings release we issued today, which can be assessed using the investor relations portion of our website. I will now turn the call over to our CEO. Bill?\nBill Brennan: Thank you, Dan. I'll begin by providing an overview of our fiscal Q3 results and our outlook for the future. Our CFO, Dan Fleming, will then provide a detailed review of our Q3 financial results and share our expectations for fiscal Q4. For Q3, Credo reported revenue of $53.1 million and non-GAAP gross margin of 62.2%. These results and our future growth expectations continue to be driven by the accelerating opportunity for high speed and energy efficient connectivity solutions throughout the data infrastructure market. Our connectivity solutions include Active Electrical Cables or AECs, Optical DSPs, laser drivers, and TIAs, Line Card PHYs, SerDes chiplets and SerDes IP licensing, each leveraging our SerDes technology. Core to Credo's success is our SerDes technology, which is the fundamental connectivity building block of all of our solutions. Credo continues to invest deeply in SerDes' architectures that enable application-specific solutions, optimized for speed, reach performance, energy efficiency and cost. Our 100 gig per lane SerDes portfolio spans process geometries from 12 nanometer to 3 nanometer, with optimized reach performance from the longest reach links to the most power sensitive die-to-die links for Chiplets. Credo will continue our innovation for 200 gig per lane SerDes as the opportunity to differentiate increases, specifically related to the optimization of tradeoffs between process geometry, DSP architecture, performance and energy efficiency. Credo SerDes technology expertise, combined with our system-level, customer-focused design approach has led to our success with a diverse and growing set of industry-leading customers. In 2023, the technology industry experienced an inflection point driven by Generative AI applications. The acceleration in the deployment of AI clusters has put high-speed connectivity on center stage, given the fundamental need for higher bandwidth. For Credo, this need for higher bandwidth translates to the demand for higher speed, higher density and more energy-efficient connectivity solutions. This plays directly to Credo's strength and underpins our growth expectations. I'll now provide more detail of our overall business. First, I'll discuss our AEC business, where Credo continued to build momentum during the third quarter. We believe our AEC leadership derives from our comprehensive systems level approach to the AEC market. We've built this from the ground up over many years and as a result, we now have the ability to quickly innovate to support the diverse AEC needs of our customers. Given increasing single lane speeds, and the shortcomings of both passive copper cables and active optical cables and transceivers, we foresee continuing adoption of AEC's for in-rack connectivity. We expect U.S. hyperscalers to remain the majority portion of AEC demand in the foreseeable future. Many of these customers have distinct architectural requirements that demand innovation and tight collaboration between the engineering teams at Credo and the customer. We're engaged at different stages with the five U.S. hyperscalers as well as other global hyperscalers and Tier 2 data center operators. We've delivered a range of products with non-standard optimized hardware and firmware features to meet our customers' needs for port speeds from 100-gig to 800-gig, depending on the customer application. Credo continues to work closely with our first two hyperscale customers, delivering AEC solutions for both front-end and back-end Ethernet networks, as each publicly highlighted during their conferences last quarter. We're gaining better visibility with these customers into their near-term product ramps, and we're also engaged in a range of AEC solutions to address longer term roadmaps. While advanced programs of this nature take time to achieve material deployment rates, we continue to expect an inflection point in the second half of our fiscal '25. Credo is also working with additional U.S. and global hyperscalers to develop 400-gig and 800-gig AEC solutions that we expect will yield significant revenue for Credo in the future as next generation network architectures transition to AEC solutions. Additionally, we see broader acceptance of AEC solutions among service providers and Tier 2 data centers. As a group, these customers represent a meaningful and growing revenue opportunity. Last quarter, we discussed the introduction of our P3 - Pluggable Patch Panel solution, developed in collaboration with a lead service provider. Over the past quarter, we've been encouraged by customer feedback that the combination of the P3 and the AECs can help overcome multiple networking challenges related to power and thermal distribution, lane speed disparities, and the trade-offs of operational efficiency, latency and power. We expect to generate meaningful future revenue as the P3 enables AECs to be easily utilized in a more broad set of operational opportunities, thereby expanding our addressable market. In summary, we were very pleased with our AEC progress in Q3, and due to our expanding customer base and focus on innovation, we expect further progress in Q4, fiscal '25 and beyond. Now, regarding our optical solutions, Credo continues to gain traction in the optical DSP market. During the third quarter, we continued production shipments of optical DSPs to multiple global hyperscale end customers for a variety of applications across numerous port speeds. We closely target the combination of optical module partners and hyperscale end customers, and we're making progress on optical DSPs for 400-gig and 800-gig optical transceiver and AOC opportunities. Enabled by our SerDes' design approach, Credo wins by delivering a compelling combination of performance, energy, efficiency and value, as well as focusing on innovative ways to solve complex customer needs. Last quarter, we talked extensively about the industry call for action for better power efficiency for 800-gig and 1.6T optical solutions. As we discussed, we believe eliminating the DSP with the Linear Pluggable Optics or LPO architecture is simply too far a leap, especially for 1.6T. Credo quickly responded with our innovative Linear Receive Optics or LRO DSP architecture that directly addresses the power challenge while delivering better signal integrity, maintaining industry standards, IEEE compliance in interoperability and extending to 1.6T solutions. Since our discussion last quarter, we've made meaningful progress. Our first 800-gig LRO DSP partner has built and tested 800-gig optical modules, and the results are exactly as expected, successfully delivering on the promise of much reduced power and great signal integrity while overcoming the shortfalls of the aspirational LPO architecture. Next month at OFC in San Diego, we'll be demonstrating both 800-gig LRO DSP and full DSP solutions, highlighting our progress. We'll be demonstrating 800-gig solutions with five different optical module partners. Our 1.6T roadmap includes both LRO DSP and full DSP solutions with 200-gig per lane speeds, with our top priorities being energy efficiency and signal integrity, which are both critical to achieve robust 1.6T optical solutions. We believe the growth in our optical business will be primarily driven by U.S. hyperscaler end customers, with further contributions from global hyperscalers. I'll now discuss our Line Card PHY business, which delivered another solid quarter in Q3. In this segment, our customers include networking OEMs and hyperscalers, and our products include Retimers, Gearboxes, and MACsec PHYs for data encryption. Our customers are the leaders in the space. We have close working relationships and our design wins typically have long lifecycles once they ramp to production, contributing nicely to our overall results. In the upcoming months, we'll tape out our customer sponsored 5-nanometer 1.6T MACsec PHY, and our power optimized 1.6T retimers and gearboxes. Credo is among the industry leaders for 50-gig and 100-gig per lane line card PHY applications. We have many customers that have deployed our 50-gig per lane solutions in production, and we count more than ten customers designing in our 100-gig per lane Screaming Eagle line card PHYs. And now turning to our IP and Chiplet business. Our SerDes IP and SerDes Chiplet businesses continue to be a strategic component of our overall business. These solutions enable our partners to address the ASIC market for next generation solutions. Due to revenue recognition rules, our SerDes IP revenue can vary meaningfully from quarter to quarter, which is what we saw in Q3, and we will likely see in the upcoming quarters. Our funnel for SerDes licensing opportunities remains strong, bolstered by the increased opportunity on ASICs with high-speed SerDes for data center applications. We have a comprehensive portfolio of SerDes IP for our ASIC customers, including 100-gig per lane SerDes across the broadest range of process geometries from 12 nanometers to 3 nanometers, and the broadest range of reach performance from long reach to die-to-die reach. Our SerDes IP offering enables our ASIC partners to optimize their solutions for process geometry, reach and power. Last quarter, our chiplet business was highlighted by a win with significant NRE at one of our leading customers for a next-generation, five nanometer chiplet solution which speaks loudly regarding our differentiated SerDes portfolio. When complete, Credo will be able to market and sell this chiplet to the broad market. Overall, we remain optimistic about the prospects of the chiplet category, given our results to date, and due to our belief that chiplets will be a key enabler in the most advanced system solutions. In summary, we're pleased with our results for fiscal Q3, and we're optimistic about the increasing market demand for high-speed connectivity. Credo's competitive advantage is driven by our focus and execution on our core SerDes technology, and that leads Credo to being one of few companies capable of delivering the necessary breadth of connectivity solutions at the highest speeds, while optimizing for energy efficiency and system cost. For these reasons, we expect continued long-term growth across a diversified customer base, and a diversified set of connectivity applications. I'll now turn the call over to our CFO, Dan Fleming. Dan will provide additional financial details, and then we'll be happy to take questions. Thank you.\nDan Fleming: Thank you, Bill, and good afternoon. I'll first review our Q3 results and then discuss our outlook for Q4 of fiscal '24. In Q3, we reported revenue of $53.1 million, up 20% sequentially, and down 2% year-over-year. Our IP business generated $1.3 million of revenue in Q3, down 83% sequentially, and down 90% year-over-year. IP remains a strategic part of our business, but as a reminder, our IP results may vary from quarter-to-quarter, driven largely by specific deliverables to pre-existing or new contracts. While the mix of IP and product revenue will vary in any given quarter over time, our revenue mix in Q3 was 2% IP, below our long-term expectations for IP, which is 10% to 15% of the revenue. We expect IP, as a percentage of revenue to be within our long term expectations for fiscal '24 and near the high-end of the range. Our product business generated $51.8 million of revenue in Q3, up 41% sequentially and up 24% year-over-year. Our top three end customers were each greater than 10% of our revenue in Q3. Our team delivered Q3 non-GAAP gross margin of 62.2% above the high-end of our guidance range and up 235 basis points sequentially. Our IP non-GAAP gross margin generally hovers near 100%, and was 92.7% in Q3. Our product non-GAAP gross margin was 61.5% in the quarter, up 877 basis points sequentially, due to a large increase in product NRE revenue, and up 1,420 basis points year-over-year. Total non-GAAP operating expenses in the third quarter were $30.6 million, above the high-end of our guidance range, up 13% sequentially and up 19% year-over-year. Our OpEx increase was a result of a 24% year-over-year increase in R&D as we continue to invest in the resources to deliver innovative solutions. Our SG&A was up 12% year-over-year. Our non-GAAP operating income was $2.4 million in Q3, compared to a non-GAAP operating loss of $0.7 million last quarter, due to increased topline leverage. Our non-GAAP operating margin was 4.6% in the quarter compared to a non-GAAP operating margin of negative 1.7% last quarter, a sequential increase of 622 basis points. We reported non-GAAP net income of $6.3 million in Q3, compared to non-GAAP net income of $1.2 million last quarter. Cash flow used in operations in the third quarter was $1 million. CapEx was $5.1 million in the quarter driven by R&D equipment and production mask spending. And free cash flow was negative $6.1 million, an increase of $3.1 million year-over-year. We ended the quarter with cash and equivalents of $409.1 million, an increase of $168.6 million from the second quarter. This increase in cash came from the net proceeds of our successful follow-on offering of shares completed in December of 2023. We remain well capitalized to continue investing in our growth opportunities while maintaining a substantial cash buffer. Our accounts receivable balance increased 36.8% sequentially to $44.8 million, while day sales outstanding increased to 77 days up from 68 days in Q2. Our Q3 ending inventory was $31.5 million, down $4.3 million sequentially. Now, turning to our guidance, we currently expect revenue in Q4 of fiscal '24 to be between $59 million and $62 million, up 14% sequentially at the midpoint. We expect Q4 non-GAAP gross margin to be within a range of 64% to 66%. We expect Q4 non-GAAP operating expenses to be between $33 million and $35 million, and we expect Q4 diluted weighted average share count to be approximately 180 million shares. We are pleased to see fiscal year '24 playing out as expected. The rapid shift to AI workloads has driven new and broad-based customer engagement, which has continued to enable us to diversify our revenue through fiscal year '24 and beyond. As a result, we look forward to driving operating leverage in the coming quarters. And with that, I will open it up for questions.\nOperator: [Operator Instructions] Our first question comes from Toshiya Hari with Goldman Sachs. Your line is now open.\nToshiya Hari: Hi, good afternoon. Thank you so much for taking the question. Bill, I wanted to ask you how you're thinking about your business over the next year or so. I thought the way you framed the AEC opportunity and the optical DSP opportunity, both in the near-term and the medium term was pretty consistent with how you sort of framed it three months ago. But I'm curious, just given the significant increase in AI spending infrastructure broadly, have you seen any of your customer projects either get pulled in or the sizing increase over the past 90 days, or the way you're thinking about the additional customer in AEC, the engagements on the DSP side, are they pretty consistent with 90 days ago? And then I have a follow up.\nBill Brennan: Sure. I would say, there - generally speaking, it's pretty consistent with what we've communicated in the past. We're really in the early innings of many of the opportunities, and we're going to see some variability as each one of these things ramp. And I can say that we feel great about the fact that we've got more irons in the fire than ever before. But I think from a revenue profile standpoint, we've been pretty consistent in saying that we see an inflection point in the second half of fiscal '25. So really, really no change.\nToshiya Hari: Got it. Okay, thank you. And then a follow up on gross margins for Dan. In the quarter, I guess even if you exclude the increase in NRE revenue, your product gross margins I thought were pretty good on a sequential basis, they improved quite nicely. What were the drivers there? And if you can provide a bridge from 62.2% last quarter to, I guess, 65% at the midpoint for this quarter, that would be helpful. And is there anything kind of one time in nature embedded in the 65% for this quarter? Thank you.\nDan Fleming: Yes. That's a great pickup on your part because as we look at things, we thought kind of the hidden story is really that due to increasing scale and product mix, if you exclude NRE from our product gross margin, it was up 328 basis points sequentially, as you say, from 50% to 53%. And that's in line with our messaging that we've given historically. We think we're well on track for attaining our long term gross margin expectation, which is again 63% to 65% within the next two years. And this is kind of a key part of that story, is increasing product margins. Now, when it comes to Q4, the other thing I mentioned or alluded to, IP in Q3 was only 2% of our overall revenue mix. Yet we said in our prepared remarks that we expect for the full year that IP as a percentage of the overall revenue mix will be at the high end of our long term range of 10% to 15%. So if you look year to date, IP has only been 9% of our overall revenue mix. So you could expect Q4 to be very strong in terms of IP deliverables, which again, we recognize revenue upon those deliverables of IP databases under ASC 606. So, IP has been quite variable, quarter-to-quarter. Throughout FY'24, it's been highly variable. It's been very illustrative of that pattern. So, in a sense, you might say the IP portion contributing to the gross margin being 65% at the midpoint, that can, that's a variable part of it. But having said that, the underlying thing to focus on is really product gross margin exclusive of NRE. And the trend there has been very favorable to us due to product mix and increasing scale.\nOperator: Thank you. One moment for our next question. Our next question comes from Karl Ackerman with BNP Paribas. Your line's now open.\nKarl Ackerman: Yes. Thank you, gentlemen. You tend to not be dictated by the seasonal variations of market each quarter. But since you happen to sell primarily into front end traditional server market applications, I'm curious to hear whether you are seeing a cyclical recovery in traditional servers as new data centers are being built to really ameliorate the power limitation of installing GPUs, and therefore you are seeing that happen in ramp now.\nBill Brennan: So, I think that the way that we view our AEC business is really broken out into two parts, front-end networks and back-end networks. And so the front-end connections that we're making for general compute as well as AI, they look very similar in a sense. I can tell you that the most history that we've got on the front end network connections is really with our first AEC customer, Microsoft. And if we think back on history, the number of front end connections associated with AI clusters is fewer than - it's fewer in an overall volume sense because you've got one front end network connection for maybe six to eight GPUs, whereas there's one connection for every general compute server in comparison. And so, we saw a big reduction in the forecast, which would clearly imply that they made a huge pivot towards AI. I can say that we've always expected a rebalancing, and I think based on forecasts, I think we see that coming within the next 12 months, probably back-end weighted on the 12 month forecast. So I do think that we're seeing some of that movement. But again, we don't really get super specific visibility on that.\nKarl Ackerman: I see. Thanks for that. For my follow up, I was hoping you could address how large is your chiplet business today? And is that broadening into multiple customers or is it still dominated by a single customer at this point? Thank you.\nBill Brennan: We've got two customers in production now. One is Tesla and one is Intel, and both have been publicly discussed. The expectation that we've had, we've been working on chiplets for several years, and we've been bullish on the space, probably before the industry at large was talking about it. I think that the discussion that we've had about this recently is that it has become a nice portion of our business. But if I think about long term, and I think about how the different businesses will break down, this is not going to probably rival the AEC business that we've got or the optical DSP business long term. So, it'll be a smaller component of our business, but still very meaningful. And to answer your - the second part of your question, we've got a handful of customers that are engaging with us for chiplet designs. Understand that chiplets we design will be generally available to the market, even though typically we have an initial sponsor that moves us in a direction on a given spec.\nOperator: Thank you. One moment for our next question. Our next question comes from Tore Svanberg with Stifel. Your line's now open.\nTore Svanberg: Yes, thank you. Bill, I was hoping you could update us on the AEC market, perhaps just more in sort of form factor, right, so I mean, it's very clear that the AEC market is heating up. We're starting to see more competitors in the market, but everybody seems to take a different approach on the form factor, system versus chip. So, I was hoping you could update us on where you see the market evolving over the next 18 months to 24 months. And again, filling the entire system is still the way to go?\nBill Brennan: Yes, I think that the key for us is that we see the work required to bring an AEC to production with great performance, high quality, high reliability. It's really the same whether one company is taking responsibility like we are, or if many companies are trying to work together and sharing responsibility. Our feeling has always been that the most effective approach to bringing these products to market quickly is to take full ownership of all aspects of the hardware and the firmware design, the entire process to qualify and bring a product to production. And then ultimately, be the responsible party for directly servicing and supporting during production. And so, there's no lack of clarity for us and our customers as to who owns the responsibility during any stage. And as a result, we've been first to samples several times and first to qualification now with several different customers. And so there's different approaches, but I think there's always going to be some signal loss as it relates to multiple parties trying to respond to urgent needs within the customer base. And so, we're feeling quite good about the efforts that we've made over the last several years in not only developing customer relationship, but also just developing a core capability. I estimate that we have more than 100 people that are dedicated to our AEC business at a system level. And so, we can also talk about if we want to make a direct apples-to-apples comparison. I think it's important to point out that our core SerDes, which is a key point that I want to emphasize, if we're head-to-head, apples-to-apples, we're always going to have the most energy efficient solutions, just given the advantages that we bring with our SerDes technology.\nTore Svanberg: Yes, that's really helpful. And as my follow up and on PAM4 DSP, and not to sort of steal away thunder from OFC, but you've had the LPO DSP out now for a few months, and I'm just wondering what the early reaction has been from customers, assuming you've been able to discuss this in more detail with your customer base.\nBill Brennan: I think the reaction has been as expected. We've seen certain customers really become very interested in this approach. Especially for the 800-gig market, there's quite a broad spectrum in the way that customers are thinking about the market. And we can go back to OFC a year ago when this whole concept of linear pluggable optics or an optical module without a DSP was really introduced. And although the call to action during OFC last year was really talking about 1.6T modules, and just the fact that the curve was almost unsustainable from a power standpoint, so looking at options. So, of course, there are certain people in the market that are investing resources in trying to play out the LPO architecture in the 800-gig space. But of course, in a sense, the 800-gig horse is already out of the barn, full DSP is what you're seeing in every 800-gig module that's being built right now. I think there's still a desire to lower power and potentially lower cost. And the key there is that our solution, which is really deploying DSP on half of the connection within the module versus what we refer to as a full DSP, we're giving a path to maintain industry standards, signal integrity, and basically overcoming all the obstacles that people face by eliminating the DSP. And so we're offering a path to a much reduced power and potentially cost. And so, it's played out quite well. We'll actually be demonstrating with two optical module partners at OFC, and we'll have first sample units from our partners being shipped into the first interested hyperscaler in the next fiscal quarter. So, we're pretty satisfied with the efforts that have been made over the last quarter in collaboration with our module partners. But I will say that as we look towards the future, we're offering great solutions that are LRO, which is half DSP and full DSP. And as we look at 200-gig per lane, or 1.6T optical DSPs, we're going to deliver both full DSP solutions and half DSP or LRO solutions at the same time. The design that we're pursuing in 3 nanometer, we've designed in that flexibility. And so it's really - we're really putting the decision in the hands of the customer. Now note that we've chosen 3 nanometer as our process geometry, based really on power efficiency. And so we believe we're going to deliver a full DSP, optical DSP that is capable of being integrated within the current connector specs and within the power ceilings that are already out there with the IEEE standard connectors.\nOperator: Thank you. One moment for our next question. Our next question comes from Matt Ramsay with TD Cowen. Your line's now open.\nMatt Ramsay: Thank you very much, guys. Good afternoon. I guess, Bill, I wanted to follow-up on kind of the tenor of the conversation you were just having in your last answer, and I guess with OFC coming up, I think my observation has been there's developed in the networking and optic space two or three sort of polarizing religious technical debates over the last 12 months with InfiniBand and Ethernet with Linear Drive versus DSP, or whether to do whole system solutions or just chips. And I guess what I wanted to ask you is, when you're engaging with your customer base and talking about solutions going forward, are you noticing that hyperscale companies are making bets in all areas here, and there's sort of room and area under the curve for companies like yourselves and your competitors that may take different approaches to all succeed because the pie is big enough, or people - or are the customer base making sort of binary decisions along some of those axes that might open or close opportunities for your company at different customers? I'm just trying to get - it seems like things have gotten very polarized around several different axis over the last 12 months, and I'd just be kind of interested in your thoughts. Thanks.\nBill Brennan: Sure. I think from our perspective, it's a little bit more clear. I think the churn that you see, the polarizing opinions in the market, those are really observers that are - or participants trying to create some momentum. The way that we view it is really the decision-making happens in the conversations that are ongoing directly with hyperscalers. We view each one of them as kind of a separate market. Each one has a different architectural strategy, each one has kind of a different timeline that they're working on. Ultimately, they all have an end objective that they're trying to strive for. But by no means does this market have a kind of a common cadence or a common roadmap between the hyperscalers. And so our big focus is, hey, let's have these conversations and identify the right connectivity solutions for each one of our hyperscale customers. And so, we're agnostic in a sense that if a customer - if a hyperscaler customer wants to go in a certain direction, we're going to try to find a way to support that direction and deliver the value that they're looking for. And so, I think it's from our perspective, yes, we see all of the hyperscalers spending efforts kind of on different ends of the spectrums that you just described. But for us, it's all part of our overall pursuit of these customers.\nMatt Ramsay: Thanks for the thoughts there. I guess as my follow-up question, Dan, I just wanted to have you reflect a little bit on the last year or so and compare where things were. I mean, obviously, the AI pivot was way more severe in magnitude and timing than I think anybody in the market really anticipated 12 months ago. But I just want to - I think your customer base has broadened, and I wonder if you could spend a few minutes talking about how you're viewing sort of quarterly revenue visibility. It's been my observation that there's some components and data center builds that are really tight, and large hyperscalers want to make sure that some components like you guys sell into certain markets are not the bottleneck of deploying systems. So just, I don't know, the confidence in quarter-to-quarter revenue visibility, given the large nature and concentration of some of your customers and maybe contrast that to where we were 12 months ago. Thanks.\nDan Fleming: Yes. Some of the key observations there are, if we go back just about a year ago today to when we had that Microsoft reset, I think we've done a very good job at executing to what we had laid out at that point in time. And what's really driven that is our product diversification throughout the year and also customer diversification as you mentioned. So as we sit here today, and we're preparing to close out our fiscal year '24, our revenue is up just modestly versus our FY23. But again, if you were to exclude Microsoft from the equation, it's up quite dramatically driven by those underlying currents, driven by AI spend, a lot of these programs are AI related that we've been given uplift for throughout the year. So, we're much more comfortable, or I'm much more comfortable right now where we stand versus say a year ago in terms of our visibility, and that's because of a diversified customer base, diversified product base. So, we're in quite a different position than we had been as we spoke a year ago.\nOperator: Thank you. One moment for our next question. Our next question comes from Vijay Rakesh with Mizuho. Your line's now open.\nVijay Rakesh: Yes. Hi. Thanks Bill and Dan. Just a quick question on the AEC side. Just wondering, I think you mentioned working in five hyperscalers, now. As you go to the back half do you see the AEC ramp broadening out to others like Google or OpenAI or Dell or any - how do you see any of the other partner ramps starting in the back half?\nBill Brennan: I think we've been pretty consistent in talking about new ramps with two of our existing customers, and both on front end networks and back end networks for future deployments. Both of these companies demonstrated last quarter at their respective conferences. And so, I think that as we look at our fiscal '25 and we talk about this inflection point in the second half, it's really related to these first two customers. And I would say that as we look at the balance of the U.S. hyperscalers for maybe what will be our third production customer, we have concluded qualification with that customer for that first program that we've been working on. There is a possibility that, that will see some contribution in the second half as well in '25, although we don't have good visibility on when they're exactly going to deploy. I don't have an idea as to timing and volume yet, but we have passed qualification. And the other two hyperscalers, five total, you know, we're in an earlier development stage, and when we think about earlier development, we're talking about architecture discussions, spec definition, product development, early samples, and those are the stages that we're working through now. And I would say that as it relates to revenue layering in, you know, to the first three - I would point to fiscal year '26, and that would be for the initial ramps. And so hopefully that gives you some color.\nVijay Rakesh: Yes. And then the - quickly on that LRO side, it's very encouraging to see how fast you came to market with that - with the receiver side DSP. And now it seems like you are ramping with a hyperscale into the next quarter? Can you talk to how big that business could be? Do you see the optical DSP ramping a whole lot faster? Obviously, it's much better margins as well.\nBill Brennan: Yes, I'm not sure if I gave you - I'm not sure if that came across correctly. An optical DSP design has a long development cycle associated with it, in a sense that the first step you've got to do is build a module with a module partner. Ultimately, there's a qualification cycle that they've got to go through before they can even be considered for qualification of hyperscaler. So I look at the timeline from start TZero to being in production as being a little bit longer, maybe significantly longer than some of the AEC experience that we've had. And so, as we're looking at kind of the near-term for optical DSP business, we're in the early innings of ramping our first U.S. hyperscale customer - end customer, through our module partner. We're seeing continued, maybe comeback in spending with the customers that we've got already qualified in China, there is a second U.S. hyperscaler that were in the stages of competing for a next generation ramp that could impact our fiscal '25. And then beyond that, I would say that there are other opportunities that we're pursuing, but from a significant volume ramp perspective, probably more in fiscal '26.\nOperator: Thank you. One moment for our next question. Our next question comes from Thomas O'Malley with Barclays. Your lines are now open.\nThomas O'Malley: Hi, guys. Thanks for taking my question. My first one is a bit of a multi-parter, so forgive me. So, in the quarter you saw a big engineering services contribution. I think Dan, you mentioned product NRE. You know, if you look historically, those have kind of come in on a quarterly basis, like $2 million to $3 million. Could you maybe give us some color why this one was so big? Is it one customer, multiple customers? Is that volume-related? Maybe a little color, if it's AEC or DSP anything that would give us a little color, just given how significant it was in the January quarter. Thank you.\nDan Fleming: Yes, certainly. Yes, as you correctly identify, historically, our product NREs range from, maybe, I'd call it $2 million to $4 million per quarter. So Q3 was higher than historically. But again, this really speaks to the value of the innovative solutions that we're bringing to market. In this particular case, it was largely for a single customer in the development as Bill mentioned, for our next generation chiplet. Now, the other piece of that, of course, as we're going down the process node geometry, this particular development was for five nanometer. So the engineering resources required for that was more engineering heavy historically than what we've had in seven nanometer and prior geometries. So those are the things that are impacting that. Now, having said all that, I don't think this sets a new bar or level of NRE engineering services. I would expect it to kind of trend back to the mean of our historical averages.\nThomas O'Malley: Got it. Super helpful. And then I just had one just on a clarification for the guide. So, you kind of said IP license for the full year is going to be kind of at the high end of your range. You're kind of saying product engineering and services goes back to the historical levels, which is like $2 million to $3 million. You've spoken pretty positively on the AEC business, but when you kind of take all those pieces together in April, other products seems to be down a little bit. Could you give us a little color on where you may be seeing some sequential weakness, that would be super helpful. Thank you very much, guys.\nDan Fleming: Yes. I don't know if I would characterize anything as sequential weakness. If you put all those pieces together, if you exclude NRE from product, it's flat to up quarter over quarter. And that's based off of a very strong sequential performance in Q3. So some programs as programs ramp, they become large, there might be pauses in certain things, just speaking generically around programs of this nature. So, nothing - no seasonal weakness, I would say.\nOperator: [Operator Instructions] One moment for our next question. Our next question comes from Vivek Arya with Bank of America Securities. Your line is now open.\nVivek Arya: Thank you for taking my questions. The quarterly product revenues are running in this $40 million, $45-ish million range. And I was hoping you could give us a sense of how much of that is AEC run rating right now? And how do you think about that quarterly trend over the next few quarters?\nDan Fleming: Yes, I would - so one of the - I mean, we don't break it out specifically by product line, but what you'll kind of infer when we file our Q and you look through that is, one of our 10% customers is going through the initial stages of a production ramp of AECs. This is our second hyperscaler that we've talked a lot about. So AEC drove a lot of the sequential growth from Q2 to Q3. In the upcoming quarters, again, as these programs start to ramp, it's a little hard to predict linearity of it, but so there may be some variability quarter-to-quarter, until we hit this second half of fiscal '25 inflection point. Hopefully that gives you some color, Vivek.\nVivek Arya: Thank you, Dan. My bigger question is, how should we get the confidence that AEC will be a preferred choice by your customers? Because they deployed a lot of GPUs last year, they are already deploying a lot of GPUs, they are deploying a lot of optical transceivers, and so far, right, they have not deployed as much AEC. So, what will change in the second half for them to start deploying more AEC and consider that a more mainstream choice as opposed to kind of a one-off or niche choice in a handful of deployments? I think that's really the key question.\nBill Brennan: Yes. I think the question is maybe related to architectures for the back-end networks and whether there are top-of-rack switches in the AI-appliance racks. And I think that if we look at the work that we're doing with our customers, I think the long-term preference is to first of all, deploy Ethernet networks. I think that's pretty commonly understood amongst the five U.S. hyperscalers. And I think that each one will have kind of a different timeline on when they go into high volume with Ethernet networks. Some of them are deploying with InfiniBand today. And I think from the standpoint of designing with top-of-rack switching versus pulling all of the connections from the AI-appliance using optical connections to the leaf spine dedicated switching network for the back end. The question, I think it's around operational efficiency and it's around how do you build and deploy these. And if you were to look at not implementing top of rack switching, you're talking about not being able to build known good racks, and then those known good racks being kind of forklift installed in the data center. You would be looking at having to assemble these clusters almost on site, which is there's a real trade off on operational efficiency. But nonetheless, all of our discussions that we're having are directly associated with feedback from customers. And I don't think anything that we're talking about is a real one off. So, as I think customers kind of execute to their long term plans, this will come more into view.\nVivek Arya: Thank you both.\nOperator: Thank you. One moment for our next question. Our next question comes from Quinn Bolton with Needham. Your line is now open.\nQuinn Bolton: Hi, guys. Thanks for taking my question. I guess, kind of, following up on Vivek's question a little bit. Last quarter you had four top customers each representing a different product line. This quarter you've talked about three 10%-plus customers. Was wondering if you can give us those 10% customers, what percent of revenues they were, and were they all representing different product lines, or are you starting to see AEC kind of coming to the top and representing the majority of revenue from at least two of your three top customers? And then I got a follow up. Thank you.\nDan Fleming: Yes. So we have - as I mentioned in my prepared remarks, we had three 10% end customers in the quarter. And again, it's important to realize that when our Q is filed in the next day or so, you'll see our end customer disclosure in our MD&A. But to give you color on what they were, the largest customer was our first AEC hyperscale customer that we've talked about. They came in at 28%, and that's followed by a lead chiplet customer, much of which was NRE driven at 23%. And then the final of the top three, which you'll be able to figure out who that is based on the warrant was our second AEC hyperscaler customer at 19%. So, two of the top three then would be AEC driven, the other being chiplet driven. So there's going to be variability in that as we go. Last quarter was a bit interesting and unique in that the top four customers all represented different - four different product lines.\nQuinn Bolton: Got it. Thanks for that additional detail, Dan. And then, I guess, Bill, you've talked a lot about the U.S. hyperscalers wanting to deploy Ethernet based backend networks instead of relying on InfiniBand. Obviously, to date, most of those GPU networks that have been deployed have been NVIDIA-based, and therefore InfiniBand is a certainly logical choice. But you've got a second GPU customer, AMD, that's beginning to ramp in meaningful volumes. I'm just wondering, can you talk about from a high level, what are you seeing across your hyperscale customer base or the backend connections in AMD, GPU networks? Are they deploying Ethernet? Are they deploying InfiniBand? Is there some other fabric? Because it certainly seem like there'd be pretty good opportunity for AECs with that AMD MI300 deployments going forward.\nBill Brennan: I think that generally speaking, you're right, but I would say that the visibility we get into the GPUs that are actually being used, it's really somewhat masked by the NIC. So we see a certain number of lanes of Ethernet at a certain speed. And really our solutions are the same. I'm sure we're connecting to NVIDIA GPUs, AMD GPUs, and internally developed GPUs as well. So I don't think that, we would be the best group to comment on the decision-making around Ethernet versus InfiniBand. I can just tell you, based on the discussions that we've had, it seems that - it seems very clear that the U.S. hyperscalers have a strong intention to deploy Ethernet. And you can go each hyperscaler and do a bottoms up on it. And I think you'll see that Microsoft is clearly out there as kind of the lead hyperscaler that is deploying with InfiniBand. But I think after that the list becomes pretty short and I think everything that we're saying it's - Ethernet is going to be preferred.\nOperator: Thank you. I'm showing no further questions at this time. Now I'd like to turn it back to Bill Brennan, CEO, for closing remarks.\nBill Brennan: Thank you very much for the questions. We really appreciate the participation and we look forward to following up on the callbacks. So much appreciated. Thank you,\nOperator: This concludes today's conference call. Thank you for participating. You may now disconnect."
    },
    {
        "symbol": "CRDO",
        "quarter": 2,
        "year": 2024,
        "date": "2023-11-29 21:50:22",
        "content": "Operator: Ladies and gentlemen, thank you for standing by. At this time, all participants are in a listen-only mode. Later, we will conduct a question-and-answer session. [Operator Instructions] I would now like to turn the conference over to Dan O'Neil, please go ahead, sir.\nDan O'Neil: Good afternoon and thank you all for joining us on our fiscal 2024 second quarter earnings call. Today I am joined by Credo's Chief Executive Officer, Bill Brennan; and Chief Financial Officer, Dan Fleming. I'd like to remind everyone that certain comments made in this call today may include forward-looking statements regarding expected future financial results, strategies and plans, future operations, the markets in which we operate, and other areas of discussion. These forward-looking statements are subject to risks and uncertainties that are discussed in detail in our documents filed with the SEC. It's not possible for the company's management to predict all risks nor can the company assess the impact of all factors on its business or the extent to which any factor or combination of factors may cause actual results to differ materially from those contained in any forward-looking statement. Given these risks, uncertainties, and assumptions the forward-looking events discussed during this call may not occur and actual results could differ materially and adversely from those anticipated or implied. The company undertakes no obligation to publicly update forward-looking statements for any reason after the date of this call to conform these statements to actual results or to changes in the company's expectations except as required by law. Also during this call, we will refer to certain non-GAAP financial measures, which we consider to be important measures of the company's performance. These non-GAAP financial measures are provided in addition to and not as a substitute for or superior to financial performance prepared in accordance with US GAAP. A discussion of why we use non-GAAP financial measures and how reconciliations between our GAAP and non-GAAP financial measures is available in the earnings release we issued today, which can be accessed using the Investor Relations portion of our website. I will now turn the call over to our CEO. Bill?\nBill Brennan: Thank you, Dan. Welcome to everyone joining our Q2 fiscal 2024 earnings call. I'll start with an overview of our fiscal Q2 results. I'll then discuss our views on our outlook. After my remarks, our CFO, Dan Fleming, will provide a detailed review of our Q2 financial results and share the outlook for the third fiscal quarter. We will then be happy to take questions. For the second quarter, Credo reported revenue of $44 million and non-GAAP gross margin of 59.9%. Our Q2 results and our future growth expectations are driven by the accelerating market opportunity for highspeed and energy-efficient connectivity solutions. We target port speeds up to 1.6 terabits per second with solutions including Active Electrical Cables or AECs, optical DSPs, laser drivers and TIAs, Line Card PHYs, SerDes Chiplets, and SerDes IP licensing, enabling us to address a broad spectrum of connectivity needs throughout the digital infrastructure market. Each of these solutions leverage our core SerDes technology and our unique customer-focus design approach. As a result, Credo delivers application-specific, highspeed solutions with optimized energy efficiency and system costs and our advantage expands as the market moves to 100-gig per lane speeds. Within the data center market today, we've seen a dramatically increasing demand for higher bandwidth, higher density, and more energy-efficient networking. This demand is driven by the proliferation of generative AI applications. For the past several years Credo has been collaborating with our customers on leading-edge AI platforms that are now in various stages of ramping production. In fact, the majority of Credo revenue will be driven by AI applications in the foreseeable future. Now, I will review our overall business in more detail. First, I'll discuss our optical business. I am pleased with the traction we've been gaining in this market. In the quarter, we continued shipping to multiple global hyperscaler end customers, and we are making progress in positioning Credo to add additional hyperscale and customers in the upcoming quarters, targeting 400-gig and 800-gig applications. Credo also has optical designs in various stages with module customers and networking OEMs for the fiber channel market, and with service providers for 5G infrastructure deployments. Credo plays a disruptive role in optical DSP market. Our fundamental SerDes technology is leveraged to provide a compelling combination of performance, energy efficiency, and system cost. Additionally, we focus on solving our customers problems and market challenges through engineering innovation. At the OFC Optical Conference in March of this year, there was an important call to action to address the unsustainable power and cost increases for optical modules in the 800-gig and 1.6T generations. Much industry discussion has ensued this year, especially related to the plausibility of the Linear Pluggable Optics architecture or LPO, also sometimes referred to as Linear Direct Drive. The LPO architecture is based on eliminating all optical DSP functionality. The industry has widely concluded that the LPO architecture will not be feasible for a material percentage of the optical module market, and that DSP functionality is critical to maintaining industry standards and interoperability, as well as achieving the bit error rate performance necessary for high yields in volume production. However, this does not mean that the industry call to action will be unanswered. Credo's response following OFC was to look at innovative ways to drastically reduce DSP power and subsequently cost through architectural innovation. Today, Credo issued a press release introducing our Linear Receive Optical or LRO DSPs. Our LRO DSP products provide optimized DSP capability in the optical transmit path-only, and eliminate the DSP functionality in the optical receive path. This innovative architecture, as optimized by Credo, effectively reduces the optical DSP power by up to 50%, and at the same time lowers cost by eliminating unneeded circuitry. Our LRO products address the pitfalls of the LPO architecture by maintaining standards and enabling interoperability among many components of an optical system. And the DSP functionality maintains the equalization performance that's critical to high yields and volume production. We've already shipped our Dove 850 800-gig LRO DSP device and evaluation boards to our lead optical and hyperscale end customers for their development and testing. While any revenue ramp will be a ways out, I view this innovation as the latest example of Credo pioneering a new product category that directly addresses the energy and system cost challenges faced by the Hyperscalers, especially for AI deployments. Regarding our AEC solutions, Credo continues to be an AEC market leader. While our initial success in our AEC business has been connecting front-end data center networks for general compute and AI appliances, we have seen an expansion in our AEC opportunity in the backend networks that are fundamental to AI cluster deployments. Due to the sheer bandwidth required by backend networks, an acceleration in single lane speeds and networking density is driving the need for AECs, given the significant benefits compared to both passive copper cables and to active optical cables or AOCs for in-rack connectivity. We continue to make progress with our first two hyperscale customers for both front-end and back-end networks, and we're especially encouraged to see Credo AECS prominently featured in the leading-edge deployments introduced at their respective conferences in November. Years in the making, we continue to maintain strong and close working relationships with our customers, and I'm pleased to say that in Q2, we made our initial shipments of 800-gig production AECs, an industry first, and again we've demonstrated our market leadership. We also continue to expand our hyperscale with customer base, with one in [indiscernible] with 400-gig AEC solutions and another in development with 800-gig AEC solutions. Additionally, we've seen the increased need for 400-gig and 800-gig AECs among Tier 2 data center operators and service providers. As a group, these customers contribute meaningful revenue to Credo. I'll also highlight one of Credo's announcements at the recent Open Compute Conference in October. Credo announced the P3, pluggable patch panel system, a multi-tool that enables service providers and hyperscalers, the freedom by using the P3 and AECs to decouple pluggable optics from core switching and routing hardware. The combination of the P3 and AECs enables network architects to optimize for power distribution and system cost, as well as to bridge varying speeds between switching and optical ports. We're engaged with several customers and believe the efforts will result in meaningful revenue in the future. To sum up, we remain confident that the increasing demand for greater networking bandwidth driven by AI applications, combined with the extraordinary value proposition of our AEC solutions, will drive continued AEC market expansion. Now, regarding our Line Card PHY business, Credo is an established market leader with our Line Card PHY solutions, which include retimers, gearboxes, and MACsec PHYs for data encryption. Our overall value proposition becomes even more compelling as the market is now accelerating to 100-gig per lane deployments. According to our customer base, Credo's competitive advantage in this market segment derives from the common thread across all of our product lines, which is leading performance in signal integrity that is, optimized for energy efficiency and system cost. We're building momentum and winning design commitments for our Screaming Eagle 1.6T PHYs and for our customer-sponsored next-generation 1.6T MACsec PHY. We remain excited about the prospects for this business with networking OEMs and hyperscale customers. Regarding our SerDes IP licensing and SerDes Chiplet businesses, credo's SerDes IP licensing business remains a strategically important part of our business. We have a complete portfolio of SerDes IP solutions that span a range of speeds, reach distances and applications with process nodes from 28 nanometer to 4 nanometer, and our initial 3 nanometer SerDes IP for 112-gig and 224-gig is in Fab now. During Q2, we secured several licensing wins across networking data center applications. Our wins include new and recurring customers, a testament to our team's execution in contributing to our customer's success. We're also enthusiastic about the prospects for our chiplet solutions. During Q2, we secured a next-generation, 112-gig, 4 nanometer SerDes Chiplet win that includes customer sponsorship. Credo is aligned with industry expectations that chiplets will play an important role in the highest-performance designs in the future. In conclusion, Credo delivered strong fiscal Q2 results. We remain enthusiastic about our business given the market demand for dramatically increasing bandwidth. This plays directly to Credo's strengths, and we're one of the few companies that can provide the necessary breadth of connectivity solutions at the highest speeds, while also optimizing for energy efficiency and system cost. As we embark on second half of fiscal 2024, we expect continued growth that supports a more diversified customer base across a diversified range of connectivity solutions. Lastly, I'm pleased to announce that, yesterday, Credo published our first ESG report, which can be found on our website. As reiterated several times today in my comments energy efficiency is built into our DNA and is a key part of our report. We aspire to be leaders across the ESG spectrum, and we strive to help enable our customers to be leaders as well. I'm very pleased with how Credo is pursuing our goals, and we look forward to continuing our positive ESG efforts. At this time, Dan Fleming, our CFO, will provide additional financial details. Thank you.\nDan Fleming: Thank you, Bill, and good afternoon. I will first review our Q2 results and then discuss our outlook for Q3 of fiscal 2024. As a reminder, the following financials will be discussed on a non-GAAP basis unless otherwise noted. In Q2, we reported revenue of $44 million, up 25% sequentially and down 14% year-over-year. Our IP business generated $7.4 million of revenue in Q2, up 165% sequentially and up 125% year-over-year. IP remains a strategic part of our business, but as a reminder, our IP results may vary from quarter-to-quarter, driven largely by specific deliverables to pre-existing or new contracts. While the mix of IP and product revenue will vary in any given quarter over time, our revenue mix in Q2 was 17% IP, above our long-term expectation for IP, which is 10% to 15% of revenue. We expect IP as a percentage of revenue to be within our long-term expectations for fiscal 2024. Our product business generated $36.7 million of revenue in Q2, up 13% sequentially and down 24% year-over-year. Our top three end customers were each greater than 10% of our revenue in Q2. In fact, our top four end customers each represented a different product line, which illustrates the increasing diversity of our revenue base. Our team delivered Q2 gross margin of 59.9% at the high end of our guidance range and up 10 basis points sequentially. Our IP gross margin generally hovers near 100% and was 95.6% in Q2. Our product gross margin was 52.7% in the quarter, down 405 basis points sequentially due to product mix and some minor inventory-related items, and up 39 basis points year-over-year. Total operating expenses in the second quarter were $27.1 million at the low end of our guidance range, down 1% sequentially and up 9% year-over-year. Our year-over-year OpEx increase was a result of an 11% increase in R&D as we continued to invest in the resources to deliver innovative solutions. Our SG&A was up 5% year-over-year. Our operating loss was $731,000 in Q2 compared to operating income of $3.2 million a year ago. The second quarter operating loss represented a sequential improvement of $5.7 million. Our operating margin was negative 1.7% in the quarter compared to positive 6.1% last year, due to reduced top-line leverage. We reported net income of $1.2 million in Q2, compared to net income of $2.2 million last year. Cash flow from operations in the second quarter was $5 million, an increase of $3.3 million year-over-year, due largely to a net reduction of inventory of $5 million in the quarter. CapEx was $2 million in the quarter, driven by R&D equipment spending and free cash flow was $3 million, an increase of $6.9 million year-over-year. We ended the quarter with cash and equivalents of $240.5 million, an increase of $2.9 million from the first quarter. We remain well capitalized to continue investing in our growth opportunities while maintaining a substantial cash buffer. Our accounts receivable balance increased 17% sequentially to $32.7 million, while day sales outstanding decreased to 68 days, down from 73 days in Q1. Our Q2 ending inventory was $35.8 million, down $5 million sequentially. Now, turning to our guidance, we currently expect revenue in Q3 of fiscal 2024 to be between $51 million and $53 million, up 18% sequentially at the midpoint. We expect Q3 gross margin to be within a range of 59% to 61%. We expect Q3 operating expenses to be between $28 million and $30 million. And we expect Q3 diluted weighted average share count to be approximately 166 million shares. We are pleased to see fiscal year 2024 continue to play out as expected. While we see some near term upside to our prior expectations, the rapid shift to AI workloads has driven new and broad based customer engagement. We expect that this rapid shift will enable us to diversify our revenue throughout fiscal year 2024 and beyond, as Bill alluded to. However, as new programs at new and existing customers ramp, we remain conservative with regard to the upcoming quarters, as we continue to gain better visibility into forecasts at our ramping customers. In summary, as we move forward through fiscal year 2024, we expect sequential revenue growth, expanding gross margins due to increasing scale and improving product mix, and modest sequential growth in operating expenses. As a result, we look forward to driving operating leverage in the coming quarters. And with that, I will open it up for questions.\nOperator: [Operator Instructions] We'll pause for just a moment to compile the Q&A roster. Our first question comes from the line of Toshiya Hari of Goldman Sachs.\nToshiya Hari: Hi. Good afternoon. Thank you so much for the question. I had two questions. First one on the revenue outlook, I just wanted to clarify, Dan, I think you mentioned sequential growth throughout the fiscal year. So April, I'm assuming is up sequentially. I guess that's the first part. And then the second part, as you think about calendar 2024, Bill, you gave quite a bit of color by product line. At a high level, the outlook sounds pretty constructive across AEC and your optical business and I guess your SerDes business as well. But if you can try to quantify the growth that you're expecting into calendar 2024 and what the top three key drivers are, that would be helpful? Thank you.\nDan Fleming: Yeah. So with regard to fiscal 2024 on your first question, generally speaking, we're very pleased with our quarterly sequential growth this year. And as we stated in our prepared remarks our Q3 guide was at the midpoint, up 18%, $52 million at the midpoint. But as we stated on our call previously, we expect modest top line growth fiscal year 2023 to 2024. So the key takeaway there, there's no change in our overall expectation for fiscal year 2024.\nBill Brennan: For the second question, I would just reiterate what Dan has said. As we look at our fiscal 2024, it's playing out very much like we expected. So really no change there. We expect, I think, what should be considered fast sequential growth and it's been driven by multiple factors. AECs, optical chiplets, really, we're firing on all cylinders.\nToshiya Hari: And Bill, sorry if I wasn't clear. Calendar 2024 or fiscal 2025, I realize it's early and you've got many moving parts, but based on customer engagements, all the color you provided across product lines, how are you thinking about the overall business into next year, if you could [Multiple Speakers]\nDan O’Neil: So, we're not providing any formal guidance right now at this point for fiscal year 2025. However, as you can imagine, we do expect meaningful growth based on all the customer engagements that we have. And as Bill mentioned, we continue to have lots of irons in the fire, but as we've stated, it takes a long time to turn a lot of these engagements into meaningful revenue, which will happen throughout the course of the year.\nToshiya Hari: Okay, got it. And then as my follow up on gross margins, as you noted in your remarks, Dan, I think your product gross margins were down sequentially in the October quarter, off a really high base in July, but curious what drove the sequential decline there? And then as you look ahead, I think you talked about gross margins expanding over the next couple of quarters. I think you said, what are the drivers there? And if you can speak to foundry costs potentially going from a headwind to something more neutral into calendar 2024 and how the diversification of your customer base helps your gross margins going forward, that would be helpful? Thank you.\nDan O’Neil: Yeah, so there was a lot to that question. Generally speaking, so as you correctly know, our Q2 product gross margin was down sequentially from Q1, which -- and if you recall, Q1 was up substantially 700 basis points from Q1. It's kind of easy to read, probably too much into these movements quarter-over-quarter at the scale that we're at right now because there are slight product mix changes from quarter to quarter. In Q2, we also had some very minor inventory-related items that impacted product gross margin. But the important thing or the most important thing is that there's no change to our long-term expectations. Our gross margin expectation over the upcoming years is to expand to the 63% to 65% range and from fiscal 2023 to 2024, you're seeing that play out, although it's not quite linear from quarter to quarter, and that'll continue to play out through next year as well.\nOperator: Thank you. Our next question comes from the line of Tom O'Malley of Barclays.\nThomas O’Malley: Hey, guys. Good afternoon and thanks for taking my question. I just wanted to clarify something you said on the call. You guys have talked previously about two customers that you're ramping with AEC. You talked about one customer in qualification with 400G and one in development with 800G. I just want to make sure you're still referring to processes that you've talked about before, or are those new developments that you guys are talking about? Thank you.\nBill Brennan: I think we've alluded to those developments in the past, but I think these are additional hyperscale customers. So the first two that we've got, November, was kind of a big month. Both of them had shows, so the Microsoft Ignite really prominently displayed their maya.ai appliance and rack. And you could -- you see the Credo AECs prominently displayed as part of that rack. So that's really something we've messaged in the past, and now it's been publicly announced and shown. And also, Amazon is having the re:Invent Conference right now as we speak. And if you look at the demos on the show floor, you'll see our 50-gig and 100-gig per lane products as part of those demonstrations. And so the two additional one we're in qual with, and we're expecting qualification to be completed sometime in the upcoming quarter, maybe give or take a month or so. And then the other one is more of a long-term plan as we're putting together, an 800-gig customer-specific solution for another hyperscaler.\nThomas O’Malley: Super helpful. And then just on the optical side, you guys had previously talked about a new 400G customer. The upside in the near term, the beginning of that ramp, or are you just seeing additional traction from customers you talked about in the past? I know that, you had -- there were some Chinese customers that you were looking to get back into rev run rate. Can you just help me understand where the strength you're seeing in the optical DSP side is coming from? Thanks.\nBill Brennan: Yeah, so generally, we continue to ramp with the partner that we're engaged with serving the US hyperscaler. So that ramp is going to happen for the next several quarters. We're also seeing further signs of life in our customer base in China. And so we've actually got -- we've got demand that we're seeing from three or four hyperscalers in China. As far as the new US. hyperscaler that we've talked about, really, that is not baked into any of the numbers that we've talked about. And so that would be if we can ultimately close that, we expect that will impact revenues in the in the fiscal 2025 time frame.\nOperator: Thank you. Our next question comes from the line of Tore Svanberg of Stifel. Tore Svanberg, your line is open. Please go ahead. Please make sure your line is unmuted and if you in speaker phone lift your handset.\nTore Svanberg: Yes. Can you hear me?\nOperator: Yes, sir. Please proceed.\nTore Svanberg: Yes. Sorry about that. Yeah. Bill, my first question was on the [indiscernible] HALO product that you just announced this afternoon. You did say that this is something that should generate revenues longer term, but I think the market is also very, very hungry for lower costs near-term. So what kind of time frame are we looking at here as far as when that product could be in production?\nBill Brennan: So I think that the first message is that we've shipped samples that are going to be built into modules. We've shipped eval boards that are going to be thoroughly tested by our lead hyperscale customer. And so [indiscernible] is really now. And so the typical development time for an optical module is on the order of -- on the order of 12 months to get to production. And that's really based on building and qualifying the module and then going through qualification with the hyperscale end customer. And so as we look at kind of best-case scenario, we're talking about something on the order of 12 months from now, so it could impact our fiscal 2025.\nTore Svanberg: That's very helpful. And as my follow-up, I know the first half of the year, there were still some headwinds, obviously, from your largest customer inventory digestion on the compute side. I'm just wondering is that now -- as we look at the January quarter, is that headwind completely behind you or is there still some lingering effects there?\nBill Brennan: Well, I think, as we think about the front-end networks at this lead customer of ours, the application is general compute as well as AI. And so, of course, there is both of these applications are kind of contributing to the digestion of the inventory that was built up as a result of the pivot earlier in the year. And so as we look at fiscal 2024, I think we've got good visibility. And exactly when it turns back on, I think we're still being conservative in a sense that we got to wait for that to really develop in our fiscal 2025.\nTore Svanberg: Great. Thank you very much.\nBill Brennan: Thank you, Tore.\nOperator: Thank you. And for our next question it comes from the line of Karl Ackerman of BNP Paribas.\nKarl Ackerman: Yeah. Thank you, gentlemen. Two questions, if I may. The first question is a follow-up from the previous one, but you are introduced using AOC solutions today to address both DSP-based and non-DSP-based optical links. How do you see the adoption of non-DSP-based solutions for back-end network connections in calendar 2024? And as you address that question, I guess, why not introduce an AEC solution for back-end networks?\nBill Brennan: So, let me take the first part of that question. Really, the two solutions that we've got for optical are what we might call a full DSP, which is kind of the traditional approach, where there's a DSP on the transmit path as well as the receive path on a given optical link. That activity is going to continue. The product that we really announced today was eliminating the DSP on the receive path and having it on the transmit path only. And so you might say that that would be half of the DSP on a typical optical and so those are really the two solutions that we're promoting. We believe that completely eliminating the DSP is really not something that's going to play out in a big way. Analysts have been out front saying that they don't see it ever being more than 10% of the market if it achieves that level. So you'd have to have a very tight control over the entire length to be able to be able to manage that. And that's just not the typical scenario in the market today. Typically people are putting together various solutions and interoperability is really the key as well as troubleshooting and ultimately yielding in production. The second part of your question was regarding AECs, and we are absolutely building AECs for backend networks. And the AECS are really covering in rack, three [indiscernible] or less solutions. There are also rack-to-rack connections, and those are all optical connections, whether they're AOCs or transceivers. And especially in that situation for rack-to-rack connectivity within a cluster, that's where we really believe that the LRO DSP is going to be highly applicable and, and really quite valuable to customers.\nKarl Ackerman: Thanks for that. For my follow-up, I wanted to pivot to your IP business. This is primarily [indiscernible] data center today, or at least a data center focused application. But over time, the idea is that as PAM3 ramps, it will transition more toward the consumer. How do you expect the end market mix of your IP business transitioning to consumer over the next few quarters? Thank you.\nBill Brennan: So as we look at our IP business primarily today, it's Ethernet. We've talked about one large consumer license that we've engaged on for consumer, and that's moving to 40-gig PAM3 for the CIO 80 or 80 gigabits per second, two lanes of 40-gig for that market. And that market is going to be out sometime in the future, probably on the order of two to three years before that ramps production. I don't expect it to be a big part of our IP business long-term. I expect that our Ethernet IP business will continue very strongly. And I also believe that from a PCIe perspective, we'll be able to talk about that as we bring our 64-gig and 128-gig solutions to market.\nOperator: Thank you. Our next question -- please standby, comes from the line Vijay Rakesh of Mizuho. Please go ahead, Vijay.\nVijay Rakesh: Yeah. Hey, Bill and Dan. Just on the PPP, the Pluggable Patch Panel, is that included in your AEC and all your -- all the three customers using it or is it -- how do you see that ramping, I guess?\nBill Brennan: Yeah, so you broke up a little on the line, but I'll answer the question by saying that this P3 was something that was developed in conjunction with a leading service provider. So they spoke about their challenges as they were connecting ZR optics to routers or switch ports. And so, this was really developed with them and their application in mind, also knowing that developing this solution, it would become a multi-tool in a sense, to be able to solve different networking problems associated with power and cooling and control plane access. And so the, our lead customer is a service provider, but we're seeing that there's also applications where this, really fits well. When we talk about the situation where switch and router port speeds are different from the optic speeds that a customer wants to use. So a customer could connect 800-gig ZR optics with 400-gig switch ports, or vice versa they could move to the fastest switches, 800-gig ports, but still use 400-gig ZR. So in a sense, this P3 system can gearbox and really seamlessly connect different speed optics with different speed ports on routers and switches. Also, from a thermal distribution standpoint, this is a really useful tool in a sense, because some customers want to use lower-cost, smaller switches that lack the power and cooling envelope for advanced ZR optics. So you would have a lot of stranded ports. So in a sense, you can take that, that thermal management away from the switch. And so there's multiple applications, we introduced this at OCP, and we realized putting out a multi-tool like this that basically enables optics to be connected directly with AECs as a different type of solution. We were surprised at the ideas that some of the engineers that came by our booth at OCP were surprised at some of the great ideas that they came up with. So generally, when we think about this product, we think about it in terms of a combination of the P3 and AECs. So we developed the P3 to basically be a catalyst for more AEC demand.\nVijay Rakesh: Got it. And so in better utilizing the stranded ports, I guess, does the P3 with the AEC actually double your content on the server to the rack or --\nBill Brennan: It's hard to say. I don't think there's a relative reference point on contact. These are new applications and with our lead customer, we think that the content can be significant. But the nice thing is, this is really an application as we prove out our lead customer, this is one that many service providers we think will pick up.\nVijay Rakesh: Got it. And then the last question on your 10% customers, how many were there in the quarter? And if you were to look out, let's say, fiscal exiting calendar 2025, any thoughts on how many 10% customer you think you would be working on?\nDan Fleming: Yeah, so for Q2, we had, as you'll see, when our Q is filed, we had three 10% end customers. Recall last quarter, we added an additional disclosure to show end customers. So you'll see the largest one was 29%. Generally, we don't disclose who our 10% customers are, but obviously the 29% one was Microsoft. Most importantly, we continue to expand our customer base throughout the year. One of the customers -- one of those three end customers is a new end customer, as you'll see in our disclosure. So it's hard to answer the latter part of your question, how many we'll add at the end of the year, but I would guess maybe four.\nOperator: Thank you. Please stand by for our next question. Our next question comes from the line of Suji Desilva of ROTH MKM.\nSuji Desilva: Hi, Bill. Hi, Dan. My question is on the competitive landscape. I'm wondering what you're seeing in the chip-based AEC efforts. Chip plus cable guys competing with you? Are you guys able to provide a faster time to market? Is that one of the reasons you're in some of these demo racks, perhaps. And maybe you can talk about the share you might think you'd be having in the AEC market versus the size? Thanks.\nBill Brennan: I think we've been consistent in saying that we don't expect to maintain 100% of the AEC market, and we do see competitors. As this product category becomes really more and more established, that is a de facto way of making short in-rack connections, we do see more competitors. The way that we're organized, for sure we're going to be able to deliver better time to market. And what we're seeing is that for the high volume applications, customers are asking for special features, special functions, and fundamentally, we are responsible for working our company. Although we're a chip company, I've built a system organization for AECs. And so we're the ones that are working directly with the hyperscalers. We're the ones having daily conversations when crunch time comes. And so for sure, we've got a time-to-market advantage. And so I think the way that this will play out, I think that our market share will ultimately play out, and I hope that we maintain more than 50% long term. And I think that's a function of being first, that's a function of having a model that delivers just a better experience with hyperscale customers directly.\nSuji Desilva: Okay. All right. Thanks, Bill. And then my other questions on the customer base and where they are in the racks. You talked about Amazon and Microsoft demoing the racks, and they seem like they're a little bit ahead of the rest of the customer base, but perhaps you can clarify that? And if so, are the other folks really close behind them, or do those guys have maybe a substantial technical lead? Just trying to figure out how the customers may waterfall in for you?\nBill Brennan: Yeah, I think from a timing standpoint, I would expect the third customer would probably ramp in the upcoming two to three quarters. It takes time for these new platforms to be deployed and then the fourth customer would be following that by a number of quarters. So I think it's one where the first two customers, of course, the architectures that they've decided to take to market, really each one of these customers is different, in a sense. So I wouldn't say that they're necessarily ahead from a technology standpoint or it's just that, they've chosen to move forward more quickly than the others.\nOperator: Thank you. Our next question comes from the line of Richard Shannon of Craig-Hallum. Richard, please make sure your line is unmuted and if you're on a speaker phone, lift your handset.\nRichard Shannon: Can you hear me now?\nOperator: Yes sir, please proceed.\nRichard Shannon: All right, great. Thanks. Dan, I have a question for you, based on the comment in your prepared remarks. So, I'm not sure if I caught it correctly, but I think you said you had three 10% customers and including your next largest one, the top four, all came -- each were supporting a different product line. I think we can all guess what the first one or -- well, first one is, but I wonder if you can delineate specifically, which product lines each of the next three customers were primarily purchasing?\nBill Brennan: Yeah, it kind of covers the broad gamut of our product lines, actually. So, obviously, the largest one being Microsoft is AEC, but for a long time our Line Card PHY business has been strong. So you could assume that would be in there. Optical DSP, we have been gaining traction there, starting with Q1, as we described last quarter. So -- and then our chiplet business we described a bit last quarter as well. So that kind of covers all of the different product lines that are materially contributing at this point in time.\nRichard Shannon: Okay. Since you didn't say it in your prepared remarks and you have talked about in this context in the past, you didn't say DSP was 10%, that I would assume that both customers at or is it one of the 10% customers is DSP?\nDan Fleming: Yeah, I mean, you could assume it's near that if it's not at that being where it is. And what we've said, we haven't changed our expectations there. We expect for next fiscal year, our target is to be at 10% or more of revenue for optical DSP. And as our first production ramp is occurring with a large hyperscaler, you might expect that we'd have a quarter or two this year where it trips 10% based upon their build schedule.\nRichard Shannon: Okay, all right, fair enough. Thanks for that characterization. I guess my second question is on product gross margins. We've had a couple of quarters of, I guess, somewhat volatile, but I think you're still talking directionally upwards over time here. Maybe specifically on the product gross margins here, with the growth in AECs, is it fair to think that that product line is gross margins, has continued to grow, and has it been somewhat steady or is it the volatility coming from that line?\nDan Fleming: Yeah, it -- I would expect all of our -- over the long term, most of our product lines will grow a bit in gross margin, really due to increasing scale. That had been a large part of our story last year, last fiscal year with the Microsoft reset. This year fluctuations in gross margin have really been more about product mix as opposed to scale. Although now that we're approaching a point where we'll be exiting the year at record levels of revenue, that scale factor will come in again. So I would expect some uplift in the AECs as well as kind of really across the board as we stay on target to achieve that 63% to 65% overall gross margin.\nOperator: Thank you. Our next question comes from the line of Quinn Bolton of Needham and Company.\nQuinn Bolton: Thanks for taking my question. I just wanted to follow up on your comments about both Microsoft Ignite and the re:Invent Conference for Amazon. You talked about the Maia 100 Accelerator racks. I think in the Microsoft blog there were certainly lots of purple cables. So it's great to see. But can you give us some sense in that Maia 100 rack, you're we talking about? As many as 48 multi-hundred gig AECs for the back end network, as well as a number of lower speed for the front end network and then for the re:Invent is -- Amazon looking at similar architectures or can you just give us some sense of what the AEC content might look like in some of those AI racks?\nBill Brennan: Yeah, on the Maya platform, I think you've got it absolutely right. The back end network is comprised of 800-gig or 100-gig per lane AECs. The front end network is also connected with Credo AECs, and those are lower speed. So you're right in terms of the number total in the rack and you could kind of visually see that when they introduced that as part of the keynote. I would say that for Amazon, they're also utilizing Credo AECs for front end connections as well as back end. And so I think just the nature of those two different types of networks, there's going to be some strong similarities between the architectures.\nQuinn Bolton: And Bill, I think in the past, you had talked about some of these AI applications, and I think you're referring to the back end networks here. You might not ramp until kind of late fiscal 2024, and then maybe not until fiscal 2025. It sounds like at least, in the Microsoft announcement, that they may be starting to ship these racks as early as kind of early next year. And so I'm kind of wondering, could you give us an update? When do you think you see volume revenue from AECs in the back end networks? Could that be over the next couple of quarters or do you still think it may be further out than that?\nDan Fleming: Well, I think that it's playing out the way that we've expected and we've spoken about this on earlier calls that in our fiscal 2024, the types of volume or revenue that we've built into the model is really based on qualification, small pilot types of build. So it's meaningful, but not necessarily what you would expect to see from a production ramp. And so as we look out into fiscal 2025, we still are being somewhat conservative about when exactly these are going to ramp. And so it was nice to see all of these things talked about publicly in November. However, deploying these at a volume scale, it's a complicated thing that they've got to work through. And so when we talk about when exactly does the linear ramp start, that's when we -- confident is going to happen in fiscal 2025, but we can't necessarily pinpoint what quarter.\nQuinn Bolton: Understood.\nOperator: Thank you. Our next question, please stand by comes from the line of Tore Svanberg of Stifel. Please go ahead, Tore.\nTore Svanberg: Yes, thank you. I just had a follow-up. So Bill, I think you've said in the past that for the AEC business with AI, you're looking at sort of a 5 times to 10 times opportunity versus general compute. And I guess related to Quinn's question, sort of the timing of how that plays out is, again, that 5 to 10, primarily on the back end side, or are you also starting to see the contribution on the front end side of the AI clusters?\nBill Brennan: Yeah, so I think generally as we talk about AI versus general compute, we're starting to think about it in terms of front-end networks and back-end networks. And so when we see a rack of AI appliances, of course, there's going to be a front-end network that looks very similar to what we see for General compute. And so to a certain extent, the way it plays out from a ratio perspective, serving the front-end network is really something that's common for both general compute and AI. You might see a larger number of general compute servers in rack. So it might say per rack, the front-end opportunity for general compute might be a little bit larger than AI. But just generally, when we think about the back-end networks, the network that is really networking every GPU within a cluster, that's where we see the big increase in overall networking density. And Quinn earlier talked about the idea of having 48 connections to the back-end network or 48 AECs within an AI appliance rack that are dedicated to the back-end network versus, say, if it's a rack with eight appliances, there'd be eight AECs for the front end. So that's where we see in an actual appliance rack. We could talk about 5 times to 6 times the volume. But then when we think about the switch racks that are part of that back-end network, there's also an additional opportunity there. And that's when we can think about the overall opportunity compared to front end being 5 to 10 times the volume.\nTore Svanberg: That's very helpful. My last question, and I have to ask you this question, just given your strong SerDes IP, but as it relates to the chiplet market, obviously, the CPU market is the first to embrace that. But are you starting to see the GPU market moving in the direction of GPUs as well, or is it just way too early for that?\nBill Brennan: I think that the standard that Intel has been promoting, the UCIe standard, I think that, that is going to be a big market for chiplets. And that for us ties in closely with the efforts that we're making on PCIe. And so, one thing I would note is that the acceleration and speeds is happening really across the board. And so we've been targeting the 64-gig PAM4, PCIe Gen 6 CXL 3 market, but I also see an acceleration for the next generation 128-gig. And so that's very much part of what's happening with this explosion in the AI market, is this need for faster and faster speeds. And so I think that you're going to see the same type of thing that's happened in Ethernet, you're going to see that happen with PCIe. And at OCP this year, we had kind of a vision piece that we presented with the possibility of CXL really, and PCIe possibly being the protocol for back-end network connectivity as well as an expansion in front end networks. So there's really exciting things coming in the future as we see that standard accelerating.\nTore Svanberg: Great. Thank you so much.\nOperator: Thank you. There are no further questions at this time. Mr. Brennan, I turn the call back over to you.\nBill Brennan: Thank you very much for the questions. We really appreciate the participation and we look forward to following up on the call backs. Thank you.\nOperator: This concludes today's conference call. You may now disconnect."
    },
    {
        "symbol": "CRDO",
        "quarter": 1,
        "year": 2024,
        "date": "2023-08-24 21:53:09",
        "content": "Operator: Ladies and gentlemen, thank you for standing by. At this time, all participants are in a listen-only mode. Later we'll conduct a question-and-answer session. [Operator Instructions] I would now like to turn the conference over to Dan O'Neil. Please go ahead, sir.\nDan O'Neil: Good afternoon, and thank you for joining us on our first quarter earnings call for fiscal 2024. Joining me today from Credo are our Chief Executive Officer, Bill Brennan; and our Chief Financial Officer, Dan Fleming. I'd like to remind everyone that certain comments made in this call today may include forward-looking statements regarding expected future financial results, strategies and plans, future operations, the markets in which we operate, and other areas of discussion. These forward-looking statements are subject to risks and uncertainties that are discussed in detail in our documents filed with the SEC. It's not possible for the company's management to predict all risks nor can the company assess the impact of all factors on its business or the extent to which any factor or combination of factors may cause actual results to differ materially from those contained in any forward-looking statements. Given these risks, uncertainties, and assumptions, the forward-looking events discussed during this call may not occur and actual results could differ materially and adversely from those anticipated or implied. The company undertakes no obligation to publicly update forward-looking statements for any reason after the date of this call to conform these statements to actual results or to changes in the company's expectations except as required by law. Also during this call, we will refer to certain non-GAAP financial measures, which we consider to be important measures of the company's performance. These non-GAAP financial measures are provided in addition to and not as a substitute for or superior to financial performance prepared in accordance with U.S. GAAP. A discussion of why we use non-GAAP financial measures and reconciliations between our GAAP and non-GAAP financial measures is available in the earnings release we issued today, which can be accessed using the Investor Relations portion of our website. I'll now turn the call over to our CEO. Bill?\nBill Brennan: Thank you, Dan, and thank you all for joining our Q1 fiscal '24 earnings call. I'll begin by providing an overview of our fiscal Q1 results. I'll then highlight what we see going forward into fiscal '24. Dan Fleming, our CFO will follow my remarks with a detailed discussion of our Q1 financial results and share the outlook for the second quarter. We would then be happy to take questions. For Q1, Credo reported revenue of $35.1 million. Additionally, we reported non-GAAP gross margin of 59.8%. Our Q1 results and future growth are driven by the accelerating market opportunity for high-speed connectivity solutions. Our electrical and optical connectivity solutions delivered leading performance of port speeds ranging from 50 gigabits per second up to 1.6 terabits per second. While we primarily serve the data center Ethernet market today, we continue to extend into other standard-based markets as the need for higher speed and more power-efficient connectivity increases exponentially. The changing workloads in the data center specifically with regards to the onset of generative AI applications are driving the demand for higher bandwidth and higher-density networking. This plays directly in to Credo's strengths. All of Credo's connectivity solutions leverage our core SerDes technology and our unique customer-focused design approach, enabling Credo to deliver optimized, secure high-speed solutions with significant benefits in power efficiency and cost. Credo continues to see increasing customer engagements across our products and IP solutions, which include active electric cables or AECs, optical DSPs, laser drivers and TIAs, Line Card PHYs, SerDes Chiplets, and SerDes IP licensing. I'll now review our overall business to give more perspective. First, regarding our AEC business. Credo remains a pioneer in the AEC market. Industry analysts forecast increasing AEC market penetration as port speeds increase for intra-rack connectivity. Our AEC solutions offer significant benefits compared to both passive direct attached copper cables, which are physically cumbersome and poor signal integrity at higher speeds, and active optical cables or AOCs which are significantly higher power and higher cost. Today, our largest customer deploys our AECs for both general compute and AI applications. Additionally, we continue to design custom AEC solutions to solve for their next-generation deployments, including our first internally developed 100 gig per lane AI deployment. At our second hyperscaler customer, our production ramp for both general compute and AI programs remains on track with expectations for continued growth throughout this fiscal year and fiscal '25. We also continue to make progress on their next-generation platforms with Credo receiving commitments from multiple 100 gig per lane AEC programs. We attribute much of our success to our existing customers to our system-level approach to the AEC market. Our approach enables us to quickly respond to customers' requests and deliver innovative feature-rich AEC solutions tailored to our customers' specific requirements. This approach has led us to making further progress with additional hyperscalers who are in various stages of evaluation and qualification of our AECs. We've also seen a growing number of Tier 2 data center operators and service providers adopting Credo AEC solutions. We have earned meaningful revenue from these customers to date and expect this customer category to grow in the future. In summary, we're happy with our progress with customers and we're encouraged by the accelerating market demand for 50-gig and 100-gig lane rates for in-rack connectivity. Regarding our optical solutions, within this market, we remain a disruptor. We leverage our core SerDes technology and customer-specific approach to deliver a compelling combination of performance, power, and cost. Credo's optical solutions comprise DSPs, laser drivers, and TIAs for 50-gig through 800-gig port applications including optical transceivers and AOCs. We expect AI deployments to drive a large optical opportunity given the high-density rack-to-rack connections with AOCs or optical transceivers in the back-end RDMA network within a cluster. I'm pleased that during Q1, we started the ramp-up of our 400-gig optical DSP for a U.S. hyperscaler. Our optical manufacturing partner is delivering 400-gig AOC solutions for an AI deployment at this hyperscaler. We expect the production ramp will continue throughout our fiscal '24 and into fiscal '25. We're also seeing demand restart from data centers in China. While too early to create meaningful expectations, Credo stands to benefit as spending returns in this market. Credo has designs in progress with several optical manufacturers and hyperscalers targeting next-generation 800-gig and 400-gig programs and we expect ongoing progress in winning production commitments. Beyond the hyperscalers, we see additional optical opportunities with networking OEMs and service providers. We remain engaged with many partners and prospective customers for Fibre Channel, 5G, OTN, and PON applications. The optical market seems to have turned the corner in the last couple of quarters. We aim to announce and demonstrate new optical solutions at upcoming optical trade shows later this calendar year and we remain optimistic about our prospects for our optical solutions business. Within our Line Card PHY business, we're an established market leader with our Line Card PHY solutions for port speeds up to 1.6 terabits per second. We think our overall value proposition becomes even more compelling as the market is now accelerating for 100-gig per lane deployments. During the first quarter, we saw design engagements increasing specifically with our Screaming Eagle 1.6 terabit per second PHYs. We've stronger customer feedback that we have again achieved a leading combination of performance, signal integrity, and power efficiency and we've already had success in winning design commitments from leading networking OEMs and ODMs. We've also made significant development progress with our customer-sponsored next-generation 1.6 terabits per second MACsec PHY, which we believe will extend our MACsec leadership well into the future for applications requiring encryption. Going forward, we expect to remain a leader in this category given our core technology differentiation and deep collaborative relationships with leading networking OEMs and ODMs, as well as hyperscalers directly. Regarding our SerDes IP licensing and SerDes chiplets business, while we see quarter-to-quarter variability in revenue for our SerDes IP licensing business, our customer traction and funnel remained consistently strong. We've seen a breadth of wins in this category, including 50-gig and 100-gig lane speeds and process nodes ranging from 5-nanometer to 28-nanometer. End applications include networking, AI, 5G, as well as a wide range of other applications. In addition to IP, we've also developed SerDes chiplets solutions with two high-profile lead customers reaching production, Credo is beginning to see meaningful revenue in our fiscal '24. One of our lead customers is Tesla and as they've publicly presented Credo is their connectivity partner for their Dojo supercomputer delivering SerDes IP for their D1 ASIC and SerDes chiplets for off-tiled connectivity. We're receiving increased interest in our SerDes chiplets from additional customers and prospects, which supports industry expectations that chiplets will play an important future role in the highest-performance designs. To sum up, we're happy with our results in fiscal Q1 and we're encouraged about demand drivers for the balance of the year and beyond. Credo's position as a market leader for high-speed connectivity solutions has been years in the making and the market acceleration towards high bandwidth solutions at low power with more networking density plays into our strengths. We continue to expect sequential growth throughout fiscal '24. We believe our growth will be led by multiple customers across our range of connectivity solutions, which would result in a more diversified revenue base as we exit fiscal '24. I'll now hand the call over to our CFO, Dan Fleming, who will provide additional details. Thank you.\nDan Fleming: Thank you, Bill, and good afternoon. I will first review our Q1 results and then discuss our outlook for Q2 of fiscal '24. As a reminder, the following financials will be discussed on a non-GAAP basis unless otherwise noted. In Q1, we reported revenue of $35.1 million, up 9% sequentially and down 24% year-over-year. Our IP business generated $2.8 million of revenue in Q1, down 51% sequentially and down 73% year-over-year. IP remains a strategic part of our business, but as a reminder, our IP results may vary from quarter to quarter. Driven largely by specific deliverables to preexisting contracts. While the mix of IP and product revenue will vary in any given quarter over time, our revenue mix in Q1 was 8% IP, below our long-term expectation for IP, which is 10% to 15% of revenue. We expect IP as a percentage of revenue to come in within our long-term expectations for fiscal '24. Our product business generated $32.3 million of revenue in Q1, up 22% sequentially and down 10% year-over-year. Our team delivered Q1 gross margin of 59.8% at the high end of our guidance range and up 160 basis points sequentially due to product mix. Our IP gross margin generally hovers near 100% and was 94.8% in Q1. Our product gross margin was 56.8% in the quarter, up 703 basis points sequentially and up 551 basis points year-over-year, due principally to product mix. Total operating expenses in the first quarter were $27.4 million within our guidance range and up 1% sequentially and 21% year-over-year. Our year-over-year OpEx increase was a result of a 30% increase in R&D as we continue to invest in the resources to deliver innovative solutions. Our SG&A was up 8% year-over-year as we built out public company infrastructure. Our operating loss was $6.4 million in Q1 compared to operating income of $5.3 million a year ago. Our operating margin was negative 18.3% in the quarter compared to 11.5% last year due to reduced top-line leverage. We reported a net loss of $4.7 million in Q1 compared to net income of $5.0 million last year. Cash flow from operations in the first quarter was $24.6 million, an increase of $36.8 million year-over-year, due largely to large receivables collected in the quarter. CapEx was $5.3 million in the quarter driven by R&D equipment spending. And free cash flow was positive $19.3 million, an increase of $36.8 million year-over-year. We ended the quarter with cash and equivalents of $237.6 million, an increase of $19.8 million from the previous quarter. This increase in cash was a result of large receivables collected during the quarter. We remain well capitalized to continue investing in our growth opportunities while maintaining a substantial cash buffer. Our accounts receivable balance decreased 43.5% sequentially to $28.0 million while days sales outstanding decreased to 73 days down from 140 days in Q4 due to collection of several large receivables. Our Q1 ending inventory was $40.8 million, down $5.2 million sequentially. Now turning to our guidance. We currently expect revenue in Q2 of fiscal '24 to be between $42 million and $44 million, up 23% sequentially at the midpoint. We expect Q2 gross margin to be within a range of 58% to 60%. We expect Q2 operating expenses to be between $27 million and $29 million. We expect Q2 basic weighted average share count to be approximately 150 million shares. We're pleased to see FY '24 continue to play out as expected. While we see some near-term upside to our prior expectations, the rapid shift to AI workloads has driven new and broad-based customer engagement. We expect that this rapid shift will enable us to diversify our revenue throughout fiscal year '24 and beyond as Bill alluded to. However, as new programs add new and existing customers ramp, we remain cautious about the back half of our fiscal year until we gain better visibility into forecasts. In summary, as we move forward through fiscal year '24, we expect sequential revenue growth, expanding gross margins due to increasing scale and improving product mix, and modest sequential growth in operating expenses. As a result, we look forward to driving operating leverage and returning to double-digit operating margins by Q4. And with that, I will open it up for questions.\nOperator: Thank you. [Operator Instructions] And our first question comes from Toshiya Hari from Goldman Sachs. Your line is now open.\nToshiya Hari: Hi, good afternoon. Thank you so much for taking the question. Just one question from me. Bill, I was hoping you can talk about the revenue drivers for the current quarter. You're guiding revenue up 23%. It's really nice to see you guys reiterate the sequential growth in the back half as well. You talked extensively about your AEC business obviously your largest customer your number two customer, you seem to talk up the Tier 2 customers there as well. And then you sounded quite good on optical. So I was hoping you could rank order, the drivers again for the current quarter on a sequential basis, and what you're most excited about as you go into the second half? Thank you.\nBill Brennan: So I can say that we're seeing strength really across the board with all of the product lines that we've got from AECs to optical to Line Card PHYs, even SerDes chiplets. It's hard for us to rank order in such a short period of time. We really see things - we see things generally moving in a positive direction. I'll say that if you look at the year, I think we've been pretty clear thus far to say that our AEC business is not going to grow this year, and that's really due to the fact that our largest customer had a big reduction in the forecast that they have for the current year. With that said, our other AEC business is growing quite rapidly as well as our other product lines. And so, we see significant growth year-over-year if we subtract the number from our largest customer. So we feel pretty good about the way that demand is shaping up. I think we've got growing visibility for this year. And again, I see us really benefiting with the acceleration in lane rates generally. And it's really positively impacting all of our businesses.\nToshiya Hari: Sorry, one quick follow-up. Thank you for that, Bill. Just the optical DSP business. You talked about the 400 gig opportunity with the U.S. hyperscaler and the production ramp in fiscal 24 through '25. You also talked about China coming back a little bit. Again, if you can - I know it's a relatively small percentage of your business today, but how should we think about the contribution from your DSP business over the next, call it 12 months to 18 months? Thank you.\nBill Brennan: Right. So I've said in the past that one of my benchmarks for this business is when do we achieve 10% of our overall revenue and I have signaled that we don't expect that to happen this year, but we've got all of the activity that would suggest, we'll see that in FY '25. With that said, I feel good about where we are the fact that we're executing to the ramp, we are seeing signs of life in China, we're qualified at multiple hyperscalers there, and as spending returns in that market we will see benefit. Now, as far as what Dan has got built-in for the year, it's not a big number for China, it's relatively small number. But I think this year we'll do a good job in approaching that 10% threshold, and then we're - I think we're on track for next year.\nToshiya Hari: Thank you.\nOperator: Thank you. And one moment for our next question. And our next question comes from Quinn Bolton from Needham & Company. Your line is now open.\nQuinn Bolton: Hi, Bill. Congratulations on the nice results. I just wanted to see if you could give a little bit more color on what you see going on at the largest customer. Obviously, they had a big forecast change back in February. Wondering if the forecasts have held fairly stable since that time? And I think if I caught it right in your prepared remarks, you mentioned AECs not only for general compute but also AI at your largest AEC customer. And I'm wondering if you could share some more details there? I thought the AI opportunity with your largest AEC customers is really more of a calendar '24 maybe even calendar '25 opportunity, so wondering if things have pulled in on that front?\nBill Brennan: So generally at our largest customer, we're still hard at work executing to the backlog and forecast that we've got. We're doing a good job there. The recent information that we've got as to how they're using our current generation of AECs, we talked about AI deployments also with the need for front-end networks and we've learned that there are certainly add employments at this customer that are using our switch cable as part of that front-end network. And so it said, relatively significant portion of the AECs that we're shipping today are going into AI applications in addition to general compute. I think it's no secret that there has been a pretty big shift in their spend that we've seen over the last six months. And as you know, it look long-term, I think we're well positioned from the standpoint of both general compute and AI. I've talked a lot about the program that we've been working on for more than a year and this is an internally developed program that's moving straight to 100 gig lanes, they're going to use AECs for [interact] connectivity between their appliances and the top of rack switches for the back-end network. And then - so I expect us to participate in both the back-end and front-end network of those clusters that are deployed. And for next-generation general compute, as they move to 50 gig lane speeds, I think we're well aligned with this customer on AEC solutions.\nQuinn Bolton: And maybe just two quick clarifications there. Was that AI internally developed AI rack because that's still kind of should we be thinking kind of later in calendar '24 or early calendar '25, any update on timing? And can you guys share what percent of revenue the largest customer was in the July quarter?\nBill Brennan: I'll let Dan answer that.\nDan Fleming: Yes. So from a 10% customer basis, what you'll see in a couple of days when we file our Q is that we had three 10% customers. The largest of which was 41% and so that largest customer has remained the largest customer over recent history. So obviously there are still a material contributor to our overall revenue mix.\nBill Brennan: And then as far as your question about timing, the timing on these new programs is really hard to nail down. I can say that it's very highly prioritized within our customer and we're very, very active in executing on that design and qualification. And so I think we've signaled that it's possible for it to - for the early part of the ramp to happen within this fiscal year, but it's really more of a fiscal '25 overall around.\nQuinn Bolton: Okay. And then for Dan. Congratulations on the gross margins, especially coming at the high end of the range with the IP mix being fairly low this quarter. You talked about margins benefiting from product mix. But it sounds like AECs are still pretty, pretty significant contribution to product revenues. Can you give us any more color on what's driving that margin strength within the product group?\nDan Fleming: Well, it really is. It goes back to the theme that you'll be picking up on here which is a lot of the current trends really are emphasizing the uptick in the need for 50 gig to 100 gig lanes and we're seeing that benefit across all of our product lines. We spoke - if I were to call out a few even though they might not be 10% of the overall revenue mix both optical and chiplets contributed materially in the quarter, line card has always been a strong performer for us. So there's just broad-based favorable product mix that we experienced within Q1. And as you rightly point out, our overall gross margin was 60% and we achieved that while IP was only 8% of our revenue mix. So we're quite pleased with the performance of our operations group and the entire organization to achieve that.\nQuinn Bolton: Yes. Nice job. Thank you.\nOperator: And thank you. And one moment for our next question. And our next question comes from Matt Ramsay from TD Cowen. Your line is now open.\nMatt Ramsay: Thank you very much. Good afternoon, guys. I guess my - for my first question, there's a lot of things that picked up in the commentary over the last 20 minutes, it seems pretty positive three different 10% customers. The guidance being what it was sort of above consensus and the expectation to grow for the remainder of the fiscal year. And so I guess I'm wondering if you could detail a little bit more A) Are you now expecting to sort of grow for the fiscal year of '24 over '23? I know you guys have kind of set a ballpark for it being flat when the reset happened in February and a lot has happened since. And it seems like with the momentum you're describing here you should easily be able to grow this year, but then there was some commentary that you gave, Bill, maybe a little bit more caution in the back half of the year in other parts of the business. Maybe you could just kind of unpack that a little bit more and if you have a new sort of expectation for the year that would be helpful. Thanks.\nDan O'Neil: Yes, let me address that for him. Thanks for the question. We - so as I mentioned in my prepared remarks actually, we do remain cautious as you say in the back half because a lot of the shift that's happened in hyperscale data center spend to AI, it's given us a lot of opportunity to engage with customers that are existing customers and new customers on new programs that we're having a lot of success in. But as these new customers and programs ramp, it's always difficult to really pinpoint exactly the impact or how quickly they will ramp. So we remain cautious in the back half as we're continuing to get better clarity in that back half. So if you were to boil that down to kind of simple math, Q1 we did what we did. Q2 if you take the midpoint of the guide, there is a little bit of upside over what the expectation was that we had said previously. But at this point, we're not giving further for the guidance in the latter half of the year.\nMatt Ramsay: Got it. No. Thank you. And understand the moving parts. I guess, as my follow-up I wanted to dig in a little bit more on the optical exciting to hear about the hyperscale win there. I'd be interested in two things. One, if you guys could spend a little bit more time maybe talking through the competitive advantage that you have in those products, particularly around sort of the N-1. The advantage that you have in some other parts. Does that apply to optical? And second, if you need to scale that optical business to support these large customer wins, what are the - I guess the points that you really need to hit and the limitations on scaling or the big sort of projects ahead of you there because it seems like that's something that might need to ramped really quickly. And I'm just kind of trying to check on the capabilities there. Thank you.\nDan O'Neil: Sure. So I would say that the N-1 factor that we've talked about definitely applies to optical. In this market, we're the disruptor. There is a strong incumbent position that Marvell has built, and they've done a very good job with that business. In reality, the optical industry is somewhat of a commodity business in the sense that this is a very difficult market for our end customers to compete in and so we play the role of disrupter and what we have to offer is excellent performance, excellent power, and with the disruptive value proposition. And that's why we've been very much welcomed. I feel great about where we are with this generation of products. It's been a long time coming that we've been able to prove absolute competitive performance in terms of bit air rates, absolutely competitive power, and delivering the kind of disruption that we expected with the N-1 process advantage that we've got. And so that's why we see a lot of activity. The Dominos I think will start to fall as one by one of our customers achieves production with hyperscalers. And from the standpoint of your question about capacity, really no issues. I expect no issues in ramping to any kind of volumes that could be expected. This is a pretty straightforward manufacturing challenge for our team. My team is used to building millions of units and with our supply partners we're very much ready from a wafer and from a substrate and from a packaging and test perspective. So I see no issues with our ability to hit the kind of volumes that we could potentially be seeing.\nMatt Ramsay: Thanks, Dan. Really appreciate it.\nOperator: Thank you. One moment for our next question. And our next question comes from Karl Ackerman from BNP Paribas. Your line is now open.\nKarl Ackerman: Yes, thank you, gentlemen. Two questions if I may. First, I guess how are you thinking about the competitive landscape for AECs? I asked it because our checks suggest that some of your peers have made incremental progress in that market, but really at the same time it sort of validates the AEC opportunity as Ethernet captures a growing portion of AI cluster. So your thoughts on that would be super helpful.\nDan O'Neil: Sure. I think that naturally, we're going to see competition make progress. One of the things that I feel very good about is the way that we're organized in comparison to the groups of companies that are trying to compete with us. We're organized in a vertical fashion, I've got more than 100 people every day, they come to work, and they work on AEC system solutions. So in a sense, they're really the customers of our IC development team. And so what that enables us to do is be very, very flexible and very quickly respond to special requests from customers. When we first thought about this market more than five years ago, we were thinking that it would be a standard products type of a market where we would put together a 400 gig on each end, 400 gig connector on each end. And then it would be kind of a standard IEEE type of standard that we'd be achieving. But the deeper that we go with this, I can tell you that all of the high-volume programs that we've talked about all of them have special features that have been implemented. And so the customer base - we've talked at length about the work that we did for Microsoft enabling the dual-core architecture and delivering an intelligent AEC solution. The fact is, others try to compete, others never achieve qualification and we're sole source of that program and that trend continued, so every one of our high-volume relationships, every one of our high-volume discussions, the engineers understand there's an opportunity for innovation and our team is well organized to achieve those differentiated features that make their rack design that much more valuable. I think that's going to be a long-term advantage for us and it's going to continue to be a competitive moat. As it relates to putting together a 400 gig kind of standard AEC or an 800 gig standard AEC, I think that's where we're going to start seeing competition make progress, but again, I think that's a smaller volume part of the market.\nKarl Ackerman: Yes. No, I appreciate that, Bill. For my follow-up, it seems the opportunity in front of you for your discrete optical DSPs is broadening and can address optical - active optical cable solutions, but I'm just curious, what are the margin implications as your discrete 400 gig DSP business ramps over the next couple of quarters? Thank you.\nDan O'Neil: Yes, we haven't - what the guidance we've given with regard to how our products kind of lay across the gross margin spectrum, we expect optical in the near and long term to be at the higher end of our product portfolio. Not too dissimilar from standalone optical companies that you've seen in the past and tracked in the past. Our Line Card PHY business, it's kind of right in the sweet spot as some of these other emerging product groups like chiplets and our AEC as a category is generally speaking below that target margin. And just for level setting, there has been no change to our long-term target model. Our long-term gross margin of 63% to 65% is our expectation, as these product lines mature and as we execute to our plans, and that's with IP contributing 10% to 15% of the overall product mix.\nKarl Ackerman: Thank you.\nOperator: And thank you. One moment for our next question. And our next question comes from Suji Desilva from ROTH MKM. Your line is now open.\nSuji Desilva: Hi, Bill. Hi, Dan. I wanted to clarify some comments you had in the prepared remarks around, I think you said Tier 2 customers, you're making progress. I just want to understand are you referring to customers beyond your first two hyperscale customers, three, four, five, and six or referring to a second-tier of cloud customers? And if it is the latter, is it traditional or newer AI - gen-AI type applications?\nDan O'Neil: So we've mentioned before that, we've engaged with multiple customers that are using our AECs and these are not hyperscalers these would be considered Tier 2 and also we've had success with service providers as well. And so we mentioned that because the product category is I think really becoming quite solidified. When a new customer comes in and is looking at our solutions, it becomes almost like an automatic effective decision just based on the fact that you can't really manage signal integrity or just basic physical size with passive copper, and optical is just a different equation on power double the power double the price, and so it becomes very easy decision. One of the announcements that we made in the last month or so was the work that we've done with Intel on their Habana Gaudi2 cluster that they've developed and that's a great example of a customer that kind of quickly made the decision to make these intra-rack and rack to rack connections, the three-meter type connections with AECs. And there is a video that they did with us and it's on our website for you to look at. That's one example of this type of customer. We've talked in the past about Comcast and within their infrastructure, they've got the need for switch racks and if you look at the big routers that are part of their infrastructure became a very easy decision for them to implement with Credo AECs. These are the types of examples, but we continue to work with what you would consider the hyperscalers and we continue to make progress. So we're at different stages of evaluation development, different stages of engagement, but not at the point where I can report, adding that third large customer.\nSuji Desilva: Okay. That's definitely helpful, thanks. And then just to clarify sort of the landscape you're selling into where some - there is Ethernet and there is some - there is certainly some InfiniBand out there. I mean, just the notion that you guys might at some point serve the InfiniBand market or that wouldn't be a future opportunity and you expect Ethernet to take share versus InfiniBand. Just color here - some basic color would definitely help us. Thanks.\nDan Fleming: Yes, I think that NVIDIA has done just a fantastic job. I'm not sure if you've seen too many back-to-back quarters like what they reported. And so, there's no question that the near-term InfiniBand is seeing great success for this the back-end networks within the NVIDIA clusters. With that said, we're involved in many, many AI next-generation deployments, all of which are Ethernet. And I think if you rely on the market forecasters, they see a very clear coexistence between InfiniBand and Ethernet long term. I think you can measure it by dollars, you can also measure by ports and the expectation I think is that the number of ports in Ethernet is going to exceed that of InfiniBand sometime in the next few years. So I think that we remain very bullish on Ethernet within AI clusters, there's no question about the amount of activity. And there's no surprise in the sense that the market is not going to be satisfied with the sole source provider. With that said, from the standpoint of our ability to do InfiniBand, there's no limitations. So I can say in the optical space, we work with companies that are delivering both Ethernet and InfiniBand solutions. And as far as the AEC standard would go, it wouldn't be a huge leap for us to develop those cables, we feel like there's a market opportunity.\nSuji Desilva: Okay. Very helpful, Bill. Thank you.\nOperator: And thank you. And one moment for our next question. And our next question comes from Tore Svanberg from Stifel. Your line is now open.\nTore Svanberg: Yes, thank you, and congratulations on 400 DSP win. Bill, on that topic. It's kind of interesting, right, because the 400 gig market is still in its early days. But we keep hearing from the industry that 800 gig is now ramping. So could you talk a little bit about your design wins and your ramps there? I mean obviously, now you've got this one win in 400 gig that's going to ramp. But what about 800, when would that start to contribute more meaningfully to revenues?\nDan Fleming: So I think we need to look at the overall opportunity and maybe break it down between front-end and back-end networks. So I think from a front-end network perspective, the slower port speeds are still going to be very popular for a while. We see the market moving to 800 for the back-end networks in AI clusters that are moving at 100 gig lane rates and so the expectation for us on 800 gig is that we probably see that as an FY '25 type of opportunity.\nTore Svanberg: Great. And I just had a follow-up on the question about the sort of caution for the second half of fiscal '24. Obviously, there's a lot of irons in the fire here, and I'm just wondering, is that caution kind of more tied to how these ramps go I'm especially thinking about your second largest AEC customer. I mean are you really concerned that it's going to grow a lot for the next few quarters and then it digests? Any further color you could add there would be great. Thanks.\nBill Brennan: Yes, so I kind of smile thinking about the expectation that we set and talking about cautiousness because if we look at the quarter-to-quarter growth rates, I think they're pretty exceptional as we climbed back to an equal level or larger level than we picked out prior to the big reset. So I think just beginning the year, I think we had plenty of challenge to maintain that kind of a growth rate, and I feel good about how we look right now. I feel good about the fact that exiting this year, I expect us to be more diversified, not just on a customer basis, but also on a product line basis, so I kind of smiled because we can take what is an exceptional story and we got to make sure that the treadmill doesn't get sped up to the point where expectations are too high. So I would just say that cautiousness is really wrapped in an incredible story of very fast growth quarter-to-quarter.\nTore Svanberg: Great. And then on the second AEC customer ramps. I think you said that's already in production. Is now sort of the main part of the ramp or does that come a little bit later?\nBill Brennan: It comes a little bit later. These programs, there's various stages of qualification early production pilot production and then really a significant ramp. And as we've signaled we've been somewhat measured in what we've included in this year and it looks like it's going to shape up as to be a much larger FY '25 ramp.\nTore Svanberg: Sounds good. Thanks for the color. Really appreciate it.\nBill Brennan: Sure.\nOperator: And thank you. And one moment for our next question. And our question comes from Brett Simpson from Arete Research. Your line is now open.\nBrett Simpson: Yes, thanks very much. Bill, I wanted to just ask on SerDes Chiplets. Can you maybe just talk a little bit about how you see the landscape here over the next couple of years? And I think you called that Tesla is a initial launch customer for SerDes chiplets. And I think they've been talking publicly about sort of installing 100 extra flop cluster over the next sort of five or six quarters. Can you maybe just talk a bit about what specifically Credo is doing within this project and more broadly just talk about how you see chiplet IO for Credo particularly now that TSMC is starting to get more and more involved in SOIC and looking at AI customers here? Thank you.\nBill Brennan: Sure. So we're happy with the relationship that we've got with Tesla. This has been multiple years that we've been working with them. I'll first start with the fact that they licensed our 100 gig per lane SerDes IP and in each one of the D1 chips they've integrated 576 of those 100 gig lanes. So when we think about total throughput, that's 57.6 terabits per second for each one of their D1 ASICs. This is why we were so attracted to working on something that was so advanced and it was even a long time ago. When we talk about 51.2 terabits per second switches, we talk about still that's not expected for some time and so I think from a SerDes IP standpoint, this is a great example of the type of work that our team can do in collaborating with the leading edge design team. If you look at their tile design, there's 25 of the D1 ASICs that are really in a five-by-five matrix and surrounding the tile are off-tile connectivity and there's 40 of our chiplets on each one of their titles. And the chiplets sort of 3.2 terabits per second also 100 gig per lane on each side, one side is XSR to manage the dotted icon activity and then off-chip is a longer reach or off title is longer reach. And so they have been public and talking about ramping. And so that's where we see meaningful revenue. The second customer that we worked with is Intel and for their 12.8T switch, which is in production now also we did chiplet design for them also 3.2 terabits per second, a little bit different interconnect between die. This was what they call it, a white bus BOW a bunch of wires on the die-to-die connection and then off package was a longer reach 30s. So we feel very good about that. We're seeing more customer interest. When we talk about the chiplet business in general, there's lots of different kinds of chiplets. We're really specializing in connectivity. So it's really SerDes chiplets are our target and we see that generally we expect it to be a large opportunity. One of the things that we've talked about in the past is our efforts for PCIe Gen 6. That effort is well underway. We see a big opportunity within the servers whether their compute or AI. Internally that network is managed with the PCIe standard. And so there is a bandwidth explosion that's happening inside the box. And so we see a large opportunity for PCIe retimers as well as chiplets and people have talked about the UCIe standard as being a die-to-die interconnect-off package would be PCIe. So we're definitely going to be in that market long-term.\nBrett Simpson: And just a follow-up on this. I mean a lot of chipmakers are talking about next architectures for AI where they physically separating out the IO from their main compute - main accelerator. Can you talk a bit about what that means for Credo? How do you position for some of these next-gen architectures? And are you engaging with any of these sorts of projects at this stage? Thanks.\nBill Brennan: Yes, I think that my understanding is what I just spoke about this UCIe standard that's being driven by Intel. We're part of that group. We're active and this is defining a standard where you can do chip-to-chip connectivity and then off-chip you can manage it in different ways. We think the right approach is to go with fast connections that are off-package and we're going to bring the same kind of advantages to that opportunity that we've brought to everything we've been involved with which is faster connectivity with better power efficiency. But that's - that I think is what maybe you're referring to. That's the way that I perceive it.\nBrett Simpson: And, Dan, maybe just a final one. In terms of the guide for next quarter, I wanted to just ask about some of the licensors for your USB for V2. Are you guiding for any royalty revenues in the current quarter from some of these licensors or not? Thanks.\nBill Brennan: No, that's all kind of beyond the fiscal year - the current fiscal year. We haven't given guidance on that yet.\nBrett Simpson: Okay, thank you.\nOperator: Thank you. And one moment for our next question. And our next question comes from Vijay Rakesh from Mizuho. Your line is now open.\nVijay Rakesh: Yes, hi. Thanks, Bill, and Dan. Just a question on the AI side. Just wondering, I know you talked about maybe bigger ramp in '24, '25, but you also talked about 5 times content getting 20 servers per rack as you go to high. Any idea - any thoughts on how - what percent of your cables now go into on the AI side. And then as we look out is the ramp on AI with Habana only or do you see opportunities on the AMD MI300 et cetera as well?\nBill Brennan: I can say that the opportunity is broad for us. Anything that's Ethernet, I think we see that as a big opportunity. As it relates to your question about overall percentages right now, we're really in high-volume production with one customer, and we've got a second lined up that is at the early stages of ramp. It's hard for me to really project without detailed forecasts, but my expectation is that both of those customers will eventually buy our solutions for their AI platforms in a significant way. And so I would say, I think general compute will continue to be large for us, but I think that AI will ultimately be where you'll see the bulk of our cables really at 100 gig lane rates in the near future.\nVijay Rakesh: Got it. And good to see you guys diversifying [3%, 10%] customers now, but I had a question on the optical, I see the DSP side, I think most treat models probably had a flat calendar '24 and a big ramp in '25, is that how we should look at it or do you see given the level of engagement on the optical IC side and it looks like things are going smoothly there that ramp could get pulled in?\nBill Brennan: Yes, I think we're comfortable with what we've discussed in the past. I think the activity that we've got right now is significant, it's leading to production commitments. We're seeing ramps begin. And I would say that I wouldn't really change the expectation I think that FY '25 is really where we expect to get the kind of production traction that would allow us to hit that milestone I talked about which is 10% of our overall revenue.\nVijay Rakesh: Got it. Great. Thanks a lot.\nOperator: And thank you. And one moment for our next question. And our next question comes from Richard Shannon from Craig-Hallum Capital Group. Your line is now open.\nRichard Shannon: Well, great, guys. Thanks for taking my question. I guess both of my question probably on DSP optical side here. You've talked about kind of early stage ramp here with a single hyperscaler. I've kind of two questions here. What sense do you get of your share position here? You're a leader or fast follower and then to what degree are we seeing some follow along with either additional designs with that customer or additional hyperscalers ramping there?\nDan O'Neil: Yes. For this first hyperscaler, I would say that we're one of their partners for the optical DSP. Hard for me to say what share we're going to have at that hyperscaler. But I think it will be significant. And with others, I think we've got a lot of activity again and it's really across the board for front-end and back-end networks. And I think we'll be in position in the future to give more color on that.\nRichard Shannon: Okay, fair enough. I'm going to follow up on another question on DSPs topic as well. I think it was Tore's question by 800 gig DSP. I think your response was something along the lines of revenue is expected somewhere in that fiscal '25 from that. What does that mean about in terms of having better visibility on wins there? Should we hear about that in the next quarter or two or is it going to be more into calendar '24 before that happens?\nDan O'Neil: Yes, I think we'll give updates when we've got something significant to report. I know that that's appreciated when we give more color, but I really want to make sure that we're locked in and we've got many, many shots on goal, so to speak, many opportunities that we're working on right now.\nRichard Shannon: Okay, fair enough. Look forward to those updates. That's all from me, Bill. Thanks.\nOperator: Thank you. There are no further questions at this time. Mr. Brennan, I will turn the call back over to you.\nBill Brennan: So thank you very much for the questions. We really appreciate the participation and we look forward to following up on the call backs. Thank you.\nOperator: This concludes today's conference call. You may now disconnect."
    }
]